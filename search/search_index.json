{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Infinigram Documentation","text":"<p>Welcome to the Infinigram documentation! Infinigram is a high-speed, corpus-based language model that uses suffix arrays for variable-length n-gram pattern matching.</p>"},{"location":"#what-is-infinigram","title":"What is Infinigram?","text":"<p>Unlike traditional neural language models or fixed-order n-grams, Infinigram:</p> <ul> <li>\u2705 Trains instantly: Models are corpora (no gradient descent needed)</li> <li>\u2705 Finds variable-length patterns: Automatically uses longest matching context</li> <li>\u2705 Provides exact matching: Every prediction traces back to actual corpus occurrences</li> <li>\u2705 Runs extremely fast: Orders of magnitude faster than neural inference</li> <li>\u2705 Enables LLM grounding: Can be mixed with neural LM probabilities for domain adaptation</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#runtime-query-transforms","title":"Runtime Query Transforms","text":"<p>Handle out-of-distribution (OOD) data through runtime query transformations:</p> <ul> <li>Case normalization: <code>lowercase</code>, <code>uppercase</code>, <code>casefold</code></li> <li>Whitespace normalization: <code>strip</code>, <code>normalize_whitespace</code></li> <li>Sequential composition: Apply multiple transforms in order</li> <li>Beam search: Explore transform combinations with <code>predict_search()</code></li> </ul>"},{"location":"#future-ood-features-planned","title":"Future OOD Features (Planned)","text":"<p>The following features are planned but deferred due to runtime performance concerns: - Typo correction: Edit distance-based corrections (requires fuzzy suffix arrays) - Semantic synonyms: WordNet-based synonym matching (requires embedding integration)</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from infinigram import Infinigram\n\n# Create model from corpus\ncorpus = b\"the cat sat on the mat\"\nmodel = Infinigram(corpus, max_length=10)\n\n# Predict next token\ncontext = b\"the cat\"\nprobs = model.predict(context)\nprint(probs)  # {115: 0.657, 97: 0.330, ...}  # 's' (sat), 'a' (at)\n</code></pre>"},{"location":"#with-runtime-transforms","title":"With Runtime Transforms","text":"<pre><code>from infinigram import Infinigram\n\n# Set default transforms at model creation\nmodel = Infinigram(corpus, default_transforms=['lowercase'])\n\n# Handles case variations automatically\ncontext = b\"The Cat\"  # Uppercase\nprobs = model.predict(context)\n\n# Or specify transforms per-call\nprobs = model.predict(b\"THE CAT\", transforms=['lowercase', 'strip'])\n\n# Beam search over transform combinations\nprobs = model.predict_search(context, search=['lowercase', 'casefold'])\n</code></pre>"},{"location":"#documentation-sections","title":"Documentation Sections","text":""},{"location":"#user-guides","title":"User Guides","text":"<ul> <li>Loading Datasets: Learn how to load and manage datasets</li> <li>Benchmarks &amp; Performance: Comprehensive benchmark results and analysis</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Transformation Scoring: Multi-factor scoring system for weighted predictions</li> </ul>"},{"location":"#development","title":"Development","text":"<ul> <li>Test Strategy: TDD strategy and coverage analysis</li> <li>Test Summary: Executive test coverage summary</li> <li>Priority Tests: Ready-to-add test implementations</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install -e .\n</code></pre> <p>For development: <pre><code>pip install -e .[dev]\n</code></pre></p>"},{"location":"#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest tests/\n\n# Run with coverage\npytest tests/ --cov=infinigram --cov-report=html\n\n# Run specific test file\npytest tests/test_infinigram.py\n</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":""},{"location":"#1-domain-specific-grounding","title":"1. Domain-Specific Grounding","text":"<p>Mix Infinigram probabilities with LLM probabilities to ground outputs in specific corpora:</p> <pre><code>llm_probs = llm.predict(context)\ncorpus_probs = infinigram.predict(context)\nfinal_probs = 0.7 * llm_probs + 0.3 * corpus_probs\n</code></pre>"},{"location":"#2-fast-pattern-matching","title":"2. Fast Pattern Matching","text":"<p>Orders of magnitude faster than neural inference for pattern-based predictions.</p>"},{"location":"#3-exact-source-attribution","title":"3. Exact Source Attribution","text":"<p>Every prediction traces back to actual corpus occurrences.</p>"},{"location":"#4-zero-shot-domain-adaptation","title":"4. Zero-Shot Domain Adaptation","text":"<p>No training required - just point at a corpus.</p>"},{"location":"#architecture","title":"Architecture","text":"<p>See Architecture for detailed system design.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions welcome! See our comprehensive Test Strategy for testing guidelines.</p>"},{"location":"#license","title":"License","text":"<p>[License information here]</p>"},{"location":"#citation","title":"Citation","text":"<pre><code>@software{infinigram2024,\n  title={Infinigram: Variable-Length N-gram Language Model},\n  author={Towell, Alex},\n  year={2024},\n  url={https://github.com/queelius/infinigram}\n}\n</code></pre>"},{"location":"ARCHITECTURE/","title":"Infinigram Architecture &amp; Vision","text":"<p>Version: 0.2.0 (Post-LangCalc Independence) Date: October 17, 2025 Status: Design Phase</p>"},{"location":"ARCHITECTURE/#vision","title":"Vision","text":"<p>Infinigram is a high-speed, corpus-based language model that leverages suffix arrays for variable-length n-gram matching. Unlike traditional neural LMs, Infinigram provides:</p> <ul> <li>Instant training: Models are corpora (no gradient descent)</li> <li>Exact matching: Finds actual patterns from training data</li> <li>Explainability: Every prediction traces back to corpus evidence</li> <li>Speed: Orders of magnitude faster than neural inference</li> <li>LLM grounding: Weight mixture with neural LM next-token probabilities</li> </ul>"},{"location":"ARCHITECTURE/#core-use-cases","title":"Core Use Cases","text":""},{"location":"ARCHITECTURE/#1-llm-fine-tuning-via-probability-mixing","title":"1. LLM Fine-tuning via Probability Mixing","text":"<pre><code># Weighted mixture of neural LM and corpus-based predictions\nfinal_probs = 0.7 * llm.predict(context) + 0.3 * infinigram.predict(context)\n</code></pre> <p>Benefits: - Ground LLM outputs in specific corpora (technical docs, legal text, etc.) - Boost domain-specific vocabulary without expensive fine-tuning - Reduce hallucinations by anchoring to real text - Real-time adaptation without retraining</p>"},{"location":"ARCHITECTURE/#2-multi-corpus-models","title":"2. Multi-Corpus Models","text":"<pre><code># Load multiple specialized corpora\ninfinigram serve \\\n  --corpus wikipedia:/data/wiki.bin \\\n  --corpus shakespeare:/data/shakespeare.bin \\\n  --corpus python-docs:/data/python-stdlib.bin \\\n  --port 8000\n</code></pre>"},{"location":"ARCHITECTURE/#3-projection-based-matching","title":"3. Projection-Based Matching","text":"<p>Beyond simple longest suffix matching, support: - Input projections: Transform query context to find better matches (e.g., lemmatization, semantic clustering) - Hierarchical matching: Weight contributions from multiple suffix lengths - Output projections: Map predicted tokens to target vocabulary</p>"},{"location":"ARCHITECTURE/#architectural-principles","title":"Architectural Principles","text":""},{"location":"ARCHITECTURE/#1-clean-api-layers","title":"1. Clean API Layers","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         CLI &amp; Shell                 \u2502  User-facing commands + REPL\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         REST API                    \u2502  HTTP endpoints (OpenAI-compatible)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      Python API (Core)              \u2502  Core Infinigram class\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    Suffix Array Engine              \u2502  Pattern matching primitives\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#2-rest-api-design-openai-compatible","title":"2. REST API Design (OpenAI-Compatible)","text":""},{"location":"ARCHITECTURE/#completions-endpoint","title":"Completions Endpoint","text":"<pre><code>POST /v1/completions\nContent-Type: application/json\n\n{\n  \"model\": \"wikipedia\",\n  \"prompt\": \"The capital of France is\",\n  \"max_tokens\": 10,\n  \"temperature\": 1.0,\n  \"top_k\": 50\n}\n\nResponse:\n{\n  \"id\": \"cmpl-...\",\n  \"object\": \"text_completion\",\n  \"created\": 1697558400,\n  \"model\": \"wikipedia\",\n  \"choices\": [{\n    \"text\": \" Paris\",\n    \"index\": 0,\n    \"logprobs\": {...},\n    \"finish_reason\": \"stop\",\n    \"metadata\": {\n      \"match_length\": 4,\n      \"confidence\": 0.89,\n      \"corpus_position\": 1234567\n    }\n  }]\n}\n</code></pre>"},{"location":"ARCHITECTURE/#chat-endpoint","title":"Chat Endpoint","text":"<pre><code>POST /v1/chat/completions\nContent-Type: application/json\n\n{\n  \"model\": \"python-docs\",\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"How do I read a file in Python?\"}\n  ],\n  \"max_tokens\": 100\n}\n</code></pre>"},{"location":"ARCHITECTURE/#models-management","title":"Models Management","text":"<pre><code>GET /v1/models\nPOST /v1/models/load\nDELETE /v1/models/{model_id}\nGET /v1/models/{model_id}/stats\n</code></pre>"},{"location":"ARCHITECTURE/#3-python-api-enhanced-core","title":"3. Python API (Enhanced Core)","text":"<pre><code>from infinigram import Infinigram, InfinigramServer\n\n# Basic usage (unchanged for backward compatibility)\nmodel = Infinigram(corpus, max_length=20)\nprobs = model.predict(context, top_k=10)\n\n# Enhanced: Multi-length matching with weights\nprobs = model.predict_weighted(\n    context,\n    min_length=1,\n    max_length=10,\n    weight_fn=lambda length: length ** 2  # Quadratic weighting\n)\n\n# Projection-based matching\nprobs = model.predict_projected(\n    context,\n    input_projection=\"lemmatize\",\n    output_projection=\"top_frequent_10k\"\n)\n\n# Corpus management\nmodel.add_corpus(new_texts, corpus_id=\"technical_docs\")\nmodel.remove_corpus(\"old_corpus\")\n\n# Model serving\nserver = InfinigramServer(port=8000)\nserver.add_model(\"wiki\", corpus_path=\"wiki.bin\")\nserver.add_model(\"code\", corpus_path=\"github.bin\", max_length=50)\nserver.start()\n</code></pre>"},{"location":"ARCHITECTURE/#4-cli-design","title":"4. CLI Design","text":"<pre><code># Training (corpus building)\ninfinigram build wikipedia.txt -o wikipedia.igram --max-length 20\ninfinigram build *.txt -o combined.igram --merge\n\n# Serving\ninfinigram serve wikipedia.igram --port 8000\ninfinigram serve wikipedia.igram code.igram --port 8000\n\n# Interactive shell\ninfinigram shell wikipedia.igram\n&gt; load shakespeare.igram as shakespeare\n&gt; predict \"to be or not to\"\n&gt; set max_length 15\n&gt; set weight_fn quadratic\n&gt; stats wikipedia\n&gt; exit\n\n# One-shot predictions\ninfinigram predict wikipedia.igram \"The capital of\"\ninfinigram complete --model wiki --text \"Once upon a\" --max-tokens 50\n\n# Model inspection\ninfinigram info wikipedia.igram\ninfinigram stats wikipedia.igram\ninfinigram search wikipedia.igram \"machine learning\"\n</code></pre>"},{"location":"ARCHITECTURE/#5-shell-stateful-repl","title":"5. Shell (Stateful REPL)","text":"<pre><code># Interactive shell with state management\n$ infinigram shell\n\ninfinigram&gt; load wikipedia.igram as wiki\nLoaded: wiki (125M tokens, max_length=20)\n\ninfinigram&gt; load shakespeare.igram as shakespeare\nLoaded: shakespeare (884K tokens, max_length=15)\n\ninfinigram&gt; models\n- wiki: 125M tokens, max_length=20\n- shakespeare: 884K tokens, max_length=15\n\ninfinigram&gt; use wiki\nActive model: wiki\n\ninfinigram&gt; predict \"The capital of France is\"\nTop predictions:\n  Paris (0.856) \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n  located (0.089) \u2588\u2588\u2588\n  situated (0.034) \u2588\n\ninfinigram&gt; set temperature 0.5\ninfinigram&gt; set top_k 20\n\ninfinigram&gt; match-info \"The capital of France is\"\nLongest match: length=4 (\"capital of France is\")\nPosition: 1234567\nContext: \"...The capital of France is Paris, and it is...\"\nConfidence: 0.89\n\ninfinigram&gt; history\n1. predict \"The capital of France is\"\n2. match-info \"The capital of France is\"\n\ninfinigram&gt; export history results.json\ninfinigram&gt; exit\n</code></pre>"},{"location":"ARCHITECTURE/#advanced-features","title":"Advanced Features","text":""},{"location":"ARCHITECTURE/#1-hierarchical-suffix-weighting","title":"1. Hierarchical Suffix Weighting","text":"<p>Instead of only using longest match, combine predictions from multiple suffix lengths:</p> <pre><code># P(next | context) = \u03a3 w(k) * P(next | suffix_k)\n# where suffix_k is the k-length suffix match\n\ndef weight_function(match_length, max_length):\n    \"\"\"Weight longer matches more heavily.\"\"\"\n    return (match_length / max_length) ** 2\n\nprobs = model.predict_hierarchical(\n    context,\n    min_length=1,\n    max_length=10,\n    weight_fn=weight_function\n)\n</code></pre>"},{"location":"ARCHITECTURE/#2-input-projections","title":"2. Input Projections","text":"<p>Transform input context to find better matches:</p> <pre><code>class InputProjection:\n    \"\"\"Transform context before suffix matching.\"\"\"\n\n    def lemmatize(self, tokens: List[int]) -&gt; List[int]:\n        \"\"\"Reduce tokens to lemmas.\"\"\"\n        pass\n\n    def semantic_cluster(self, tokens: List[int]) -&gt; List[int]:\n        \"\"\"Map to semantic cluster IDs.\"\"\"\n        pass\n\n    def drop_stopwords(self, tokens: List[int]) -&gt; List[int]:\n        \"\"\"Remove common stopwords.\"\"\"\n        pass\n\n# Usage\nmodel.predict(context, input_projection=\"lemmatize\")\n</code></pre>"},{"location":"ARCHITECTURE/#3-output-projections","title":"3. Output Projections","text":"<p>Filter or transform predicted tokens:</p> <pre><code>class OutputProjection:\n    \"\"\"Filter/transform output predictions.\"\"\"\n\n    def top_k_frequent(self, probs: Dict[int, float], k: int) -&gt; Dict[int, float]:\n        \"\"\"Restrict to k most frequent vocabulary tokens.\"\"\"\n        pass\n\n    def domain_filter(self, probs: Dict[int, float], domain: str) -&gt; Dict[int, float]:\n        \"\"\"Only allow domain-specific vocabulary.\"\"\"\n        pass\n\n# Usage\nmodel.predict(context, output_projection=\"top_frequent_10k\")\n</code></pre>"},{"location":"ARCHITECTURE/#4-multi-scale-matching","title":"4. Multi-Scale Matching","text":"<pre><code># Combine evidence from different granularities\nmodel = MultiScaleInfinigram([\n    (\"char\", char_corpus, max_length=100),\n    (\"subword\", bpe_corpus, max_length=50),\n    (\"word\", word_corpus, max_length=20)\n])\n\n# Automatically blends predictions across scales\nprobs = model.predict(context, scales=[\"word\", \"subword\"])\n</code></pre>"},{"location":"ARCHITECTURE/#5-corpus-versioning-hot-swapping","title":"5. Corpus Versioning &amp; Hot-Swapping","text":"<pre><code>server = InfinigramServer()\n\n# Load initial corpus\nserver.add_model(\"v1\", corpus_v1)\n\n# Later: hot-swap without downtime\nserver.update_model(\"v1\", corpus_v2)  # Atomic replacement\n\n# A/B testing\nserver.add_model(\"experimental\", corpus_exp)\nprobs_control = server.predict(\"v1\", context)\nprobs_exp = server.predict(\"experimental\", context)\n</code></pre>"},{"location":"ARCHITECTURE/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"ARCHITECTURE/#phase-1-cleanup-core-api-current","title":"Phase 1: Cleanup &amp; Core API (Current)","text":"<ul> <li> Remove LangCalc dependencies</li> <li> Fix test imports</li> <li> Remove <code>LanguageModel</code> ABC (not needed standalone)</li> <li> Add <code>predict_weighted()</code> for multi-length matching</li> <li> Comprehensive unit tests for new APIs</li> </ul>"},{"location":"ARCHITECTURE/#phase-2-rest-api-server","title":"Phase 2: REST API Server","text":"<ul> <li> FastAPI-based REST server</li> <li> OpenAI-compatible endpoints (<code>/v1/completions</code>, <code>/v1/chat/completions</code>)</li> <li> Model loading/unloading endpoints</li> <li> Authentication &amp; rate limiting</li> <li> Streaming responses</li> <li> Docker container</li> </ul>"},{"location":"ARCHITECTURE/#phase-3-cli-shell","title":"Phase 3: CLI &amp; Shell","text":"<ul> <li> Click-based CLI with subcommands</li> <li> <code>infinigram build</code> for corpus creation</li> <li> <code>infinigram serve</code> for starting server</li> <li> <code>infinigram predict</code> for one-shot inference</li> <li> <code>infinigram shell</code> for interactive REPL</li> <li> Tab completion, history, config files</li> </ul>"},{"location":"ARCHITECTURE/#phase-4-advanced-matching","title":"Phase 4: Advanced Matching","text":"<ul> <li> Hierarchical suffix weighting</li> <li> Input projections (lemmatization, semantic)</li> <li> Output projections (filtering, mapping)</li> <li> Configurable weight functions</li> <li> Multi-scale matching (char/subword/word)</li> </ul>"},{"location":"ARCHITECTURE/#phase-5-performance-scale","title":"Phase 5: Performance &amp; Scale","text":"<ul> <li> Binary search for suffix array queries (vs current linear scan)</li> <li> Memory-mapped corpus files for large datasets</li> <li> Compressed suffix arrays</li> <li> Parallel construction</li> <li> GPU acceleration for batch inference</li> </ul>"},{"location":"ARCHITECTURE/#phase-6-ecosystem-integration","title":"Phase 6: Ecosystem &amp; Integration","text":"<ul> <li> Pre-built corpus packages (Wikipedia, Common Crawl, etc.)</li> <li> Tokenizer compatibility layer for popular models (GPT, Llama)</li> <li> LangChain/LlamaIndex integration</li> <li> Hugging Face integration</li> <li> Evaluation benchmarks</li> </ul>"},{"location":"ARCHITECTURE/#file-structure-target","title":"File Structure (Target)","text":"<pre><code>infinigram/\n\u251c\u2500\u2500 infinigram/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 core/\n\u2502   \u2502   \u251c\u2500\u2500 infinigram.py           # Core model class\n\u2502   \u2502   \u251c\u2500\u2500 suffix_array.py         # Suffix array engine\n\u2502   \u2502   \u251c\u2500\u2500 projections.py          # Input/output projections\n\u2502   \u2502   \u2514\u2500\u2500 weighting.py            # Weighting functions\n\u2502   \u251c\u2500\u2500 server/\n\u2502   \u2502   \u251c\u2500\u2500 api.py                  # FastAPI app\n\u2502   \u2502   \u251c\u2500\u2500 models.py               # Model management\n\u2502   \u2502   \u251c\u2500\u2500 auth.py                 # Authentication\n\u2502   \u2502   \u2514\u2500\u2500 streaming.py            # Streaming responses\n\u2502   \u251c\u2500\u2500 cli/\n\u2502   \u2502   \u251c\u2500\u2500 main.py                 # Click CLI entry point\n\u2502   \u2502   \u251c\u2500\u2500 build.py                # Corpus building\n\u2502   \u2502   \u251c\u2500\u2500 serve.py                # Server management\n\u2502   \u2502   \u251c\u2500\u2500 predict.py              # One-shot inference\n\u2502   \u2502   \u2514\u2500\u2500 shell.py                # Interactive REPL\n\u2502   \u2514\u2500\u2500 utils/\n\u2502       \u251c\u2500\u2500 tokenizer.py            # Tokenization utilities\n\u2502       \u251c\u2500\u2500 corpus.py               # Corpus I/O\n\u2502       \u2514\u2500\u2500 serialization.py        # Model serialization\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_core/\n\u2502   \u251c\u2500\u2500 test_server/\n\u2502   \u251c\u2500\u2500 test_cli/\n\u2502   \u2514\u2500\u2500 test_integration/\n\u251c\u2500\u2500 docs/\n\u2514\u2500\u2500 benchmarks/\n</code></pre>"},{"location":"ARCHITECTURE/#design-principles","title":"Design Principles","text":""},{"location":"ARCHITECTURE/#1-speed-first","title":"1. Speed First","text":"<p>Infinigram's killer feature is speed. Every design decision should preserve this: - Pre-computed suffix arrays (no online construction) - Memory-mapped corpora for large datasets - Avoid Python loops in hot paths (use NumPy/Cython) - Batch operations where possible</p>"},{"location":"ARCHITECTURE/#2-simplicity-composability","title":"2. Simplicity &amp; Composability","text":"<ul> <li>Unix philosophy: do one thing well (pattern matching + prediction)</li> <li>Easy to compose with other models (mixture weights)</li> <li>Clean separation: core logic, server, CLI</li> </ul>"},{"location":"ARCHITECTURE/#3-explainability","title":"3. Explainability","text":"<p>Every prediction should be traceable: - Return corpus positions of matches - Show actual text context - Confidence scores based on match quality</p>"},{"location":"ARCHITECTURE/#4-backward-compatibility","title":"4. Backward Compatibility","text":"<ul> <li>Maintain existing <code>Infinigram</code> API for current users</li> <li>Deprecation warnings before breaking changes</li> <li>Versioned REST API (<code>/v1/</code>, <code>/v2/</code>)</li> </ul>"},{"location":"ARCHITECTURE/#ideas-for-sample-efficiency","title":"Ideas for Sample Efficiency","text":""},{"location":"ARCHITECTURE/#1-fuzzy-matching","title":"1. Fuzzy Matching","text":"<ul> <li>Allow 1-2 token substitutions in suffix matching</li> <li>Use edit distance to find \"close enough\" matches</li> <li>Weight by similarity score</li> </ul>"},{"location":"ARCHITECTURE/#2-semantic-clustering","title":"2. Semantic Clustering","text":"<ul> <li>Cluster tokens by embeddings</li> <li>Match on cluster IDs instead of exact tokens</li> <li>Find longer \"semantic suffixes\"</li> </ul>"},{"location":"ARCHITECTURE/#3-frequency-based-fallbacks","title":"3. Frequency-Based Fallbacks","text":"<ul> <li>When no long match found, use shorter matches from high-frequency contexts</li> <li>Weight by corpus frequency (common phrases matter more)</li> </ul>"},{"location":"ARCHITECTURE/#4-context-expansion","title":"4. Context Expansion","text":"<ul> <li>Look for matches in expanded window (e.g., bag-of-words nearby)</li> <li>Find non-contiguous matches</li> </ul>"},{"location":"ARCHITECTURE/#5-hybrid-neural-symbolic","title":"5. Hybrid Neural-Symbolic","text":"<ul> <li>Use neural encoder for context \u2192 embedding</li> <li>Nearest neighbor search in embedding space for similar corpus contexts</li> <li>Use those contexts' continuations</li> </ul>"},{"location":"ARCHITECTURE/#performance-targets","title":"Performance Targets","text":"<ul> <li>Construction: 1M tokens/second</li> <li>Query latency: &lt;10ms for 100-token context</li> <li>Throughput: 1000+ queries/second on single CPU</li> <li>Memory: &lt;10 bytes per corpus token</li> <li>Scaling: 1B+ token corpora</li> </ul>"},{"location":"ARCHITECTURE/#success-metrics","title":"Success Metrics","text":"<ol> <li>API adoption: Used in 10+ downstream projects</li> <li>Performance: 100x faster than neural LM inference</li> <li>Accuracy: Competitive perplexity on domain-specific corpora</li> <li>LLM improvement: Measurable reduction in hallucinations when mixed with LLMs</li> <li>Ease of use: New model trained and deployed in &lt;5 minutes</li> </ol>"},{"location":"PHASE1_PLAN/","title":"Phase 1: Core API Enhancements - Implementation Plan","text":"<p>Goal: Extend Infinigram with advanced matching capabilities while maintaining backward compatibility.</p>"},{"location":"PHASE1_PLAN/#features-to-implement","title":"Features to Implement","text":""},{"location":"PHASE1_PLAN/#1-hierarchical-suffix-weighting","title":"1. Hierarchical Suffix Weighting","text":"<p>Motivation: Currently we only use the longest matching suffix. But shorter suffixes also provide valuable information. Combining predictions from multiple suffix lengths with appropriate weights can improve accuracy.</p> <p>API Design: <pre><code># New method on Infinigram class\ndef predict_weighted(\n    self,\n    context: List[int],\n    min_length: int = 1,\n    max_length: Optional[int] = None,\n    weight_fn: Optional[Callable[[int], float]] = None,\n    top_k: int = 50\n) -&gt; Dict[int, float]:\n    \"\"\"\n    Predict using weighted combination of multiple suffix lengths.\n\n    Args:\n        context: Token sequence\n        min_length: Minimum suffix length to consider\n        max_length: Maximum suffix length (None = use self.max_length)\n        weight_fn: Function mapping suffix_length -&gt; weight\n                  Default: lambda k: k (linear weighting)\n        top_k: Return top k predictions\n\n    Returns:\n        Dict mapping token -&gt; probability\n    \"\"\"\n</code></pre></p> <p>Weight Functions (in <code>infinigram/weighting.py</code>): <pre><code>def linear_weight(length: int) -&gt; float:\n    \"\"\"w(k) = k\"\"\"\n    return float(length)\n\ndef quadratic_weight(length: int) -&gt; float:\n    \"\"\"w(k) = k^2\"\"\"\n    return float(length ** 2)\n\ndef exponential_weight(base: float = 2.0) -&gt; Callable[[int], float]:\n    \"\"\"w(k) = base^k\"\"\"\n    def weight(length: int) -&gt; float:\n        return base ** length\n    return weight\n\ndef custom_weight(max_length: int, steepness: float = 1.0) -&gt; Callable[[int], float]:\n    \"\"\"Sigmoid-like weight: w(k) = 1 / (1 + exp(-steepness * (k - max_length/2)))\"\"\"\n    def weight(length: int) -&gt; float:\n        return 1.0 / (1.0 + np.exp(-steepness * (length - max_length / 2)))\n    return weight\n</code></pre></p> <p>Tests (<code>tests/test_weighted_prediction.py</code>): - Test that weighted prediction with only longest match equals regular predict - Test that shorter suffixes contribute to final prediction - Test different weight functions produce different distributions - Test min_length and max_length boundaries - Test that weights sum correctly - Test edge case: no matches at any length</p>"},{"location":"PHASE1_PLAN/#2-input-projections","title":"2. Input Projections","text":"<p>Motivation: Transform input context to find better matches. For example, lemmatization might match \"running\" with \"run\", or dropping stopwords might find longer content-word matches.</p> <p>API Design: <pre><code># New abstract base class\nclass InputProjection(ABC):\n    \"\"\"Transform context before matching.\"\"\"\n\n    @abstractmethod\n    def project(self, tokens: List[int]) -&gt; List[int]:\n        \"\"\"Transform token sequence.\"\"\"\n        pass\n\n# Concrete implementations\nclass IdentityProjection(InputProjection):\n    \"\"\"No transformation (default).\"\"\"\n\nclass SubsampleProjection(InputProjection):\n    \"\"\"Keep every nth token.\"\"\"\n    def __init__(self, stride: int = 2):\n        self.stride = stride\n\nclass TruncateProjection(InputProjection):\n    \"\"\"Keep last k tokens.\"\"\"\n    def __init__(self, max_tokens: int = 10):\n        self.max_tokens = max_tokens\n\n# Update Infinigram\ndef predict(\n    self,\n    context: List[int],\n    top_k: int = 50,\n    input_projection: Optional[InputProjection] = None\n) -&gt; Dict[int, float]:\n    \"\"\"\n    Added input_projection parameter.\n    \"\"\"\n</code></pre></p> <p>Tests (<code>tests/test_input_projections.py</code>): - Test identity projection doesn't change behavior - Test subsample projection finds matches that full context misses - Test truncate projection limits context length - Test custom projection can be implemented - Test projection with weighted prediction</p>"},{"location":"PHASE1_PLAN/#3-output-projections","title":"3. Output Projections","text":"<p>Motivation: Filter or transform the predicted token distribution. For example, restrict to top-k most frequent tokens, or filter to domain-specific vocabulary.</p> <p>API Design: <pre><code># New abstract base class\nclass OutputProjection(ABC):\n    \"\"\"Filter/transform output predictions.\"\"\"\n\n    @abstractmethod\n    def project(self, probs: Dict[int, float]) -&gt; Dict[int, float]:\n        \"\"\"Transform probability distribution.\"\"\"\n        pass\n\n# Concrete implementations\nclass IdentityOutputProjection(OutputProjection):\n    \"\"\"No transformation (default).\"\"\"\n\nclass TopKFrequentProjection(OutputProjection):\n    \"\"\"Restrict to k most frequent tokens in corpus.\"\"\"\n    def __init__(self, corpus: List[int], k: int = 1000):\n        # Compute top k frequent tokens\n        counter = Counter(corpus)\n        self.allowed_tokens = set(t for t, _ in counter.most_common(k))\n\nclass VocabularyFilterProjection(OutputProjection):\n    \"\"\"Only allow specific vocabulary tokens.\"\"\"\n    def __init__(self, allowed_tokens: Set[int]):\n        self.allowed_tokens = allowed_tokens\n\nclass ThresholdProjection(OutputProjection):\n    \"\"\"Zero out probabilities below threshold.\"\"\"\n    def __init__(self, threshold: float = 0.01):\n        self.threshold = threshold\n\n# Update Infinigram\ndef predict(\n    self,\n    context: List[int],\n    top_k: int = 50,\n    input_projection: Optional[InputProjection] = None,\n    output_projection: Optional[OutputProjection] = None\n) -&gt; Dict[int, float]:\n    \"\"\"\n    Added output_projection parameter.\n    \"\"\"\n</code></pre></p> <p>Tests (<code>tests/test_output_projections.py</code>): - Test identity projection doesn't change output - Test top-k frequent filter restricts vocabulary - Test vocabulary filter only returns allowed tokens - Test threshold projection zeros out low probabilities - Test renormalization after filtering - Test composition of multiple output projections</p>"},{"location":"PHASE1_PLAN/#implementation-order","title":"Implementation Order","text":""},{"location":"PHASE1_PLAN/#step-1-weighting-functions-simplest","title":"Step 1: Weighting Functions (Simplest)","text":"<ol> <li>Write tests for weight functions</li> <li>Implement <code>infinigram/weighting.py</code></li> <li>Verify tests pass</li> </ol>"},{"location":"PHASE1_PLAN/#step-2-hierarchical-prediction","title":"Step 2: Hierarchical Prediction","text":"<ol> <li>Write tests for <code>predict_weighted()</code></li> <li>Implement method in <code>Infinigram</code> class</li> <li>Verify tests pass</li> <li>Update documentation</li> </ol>"},{"location":"PHASE1_PLAN/#step-3-input-projections","title":"Step 3: Input Projections","text":"<ol> <li>Write tests for projection classes</li> <li>Implement <code>infinigram/projections.py</code> with <code>InputProjection</code> classes</li> <li>Update <code>predict()</code> to accept input projection</li> <li>Verify tests pass</li> <li>Update documentation</li> </ol>"},{"location":"PHASE1_PLAN/#step-4-output-projections","title":"Step 4: Output Projections","text":"<ol> <li>Write tests for output projection classes</li> <li>Implement <code>OutputProjection</code> classes in <code>infinigram/projections.py</code></li> <li>Update <code>predict()</code> to accept output projection</li> <li>Verify tests pass</li> <li>Update documentation</li> </ol>"},{"location":"PHASE1_PLAN/#step-5-integration-examples","title":"Step 5: Integration &amp; Examples","text":"<ol> <li>Write integration tests combining all features</li> <li>Create example notebook/script demonstrating Phase 1 features</li> <li>Update README with new capabilities</li> <li>Update CLAUDE.md</li> </ol>"},{"location":"PHASE1_PLAN/#success-criteria","title":"Success Criteria","text":"<ul> <li> All new tests pass (targeting 20+ new tests)</li> <li> All existing tests still pass (backward compatibility)</li> <li> Code coverage remains &gt; 90%</li> <li> Documentation updated</li> <li> Example demonstrating all Phase 1 features</li> <li> No breaking changes to existing API</li> </ul>"},{"location":"PHASE1_PLAN/#file-structure-after-phase-1","title":"File Structure After Phase 1","text":"<pre><code>infinigram/\n\u251c\u2500\u2500 infinigram/\n\u2502   \u251c\u2500\u2500 __init__.py           # Export new classes\n\u2502   \u251c\u2500\u2500 infinigram.py         # Enhanced with new methods\n\u2502   \u251c\u2500\u2500 suffix_array.py       # Unchanged\n\u2502   \u251c\u2500\u2500 weighting.py          # NEW: Weight functions\n\u2502   \u2514\u2500\u2500 projections.py        # NEW: Input/Output projections\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_infinigram.py    # Existing tests\n\u2502   \u251c\u2500\u2500 test_weighting.py     # NEW\n\u2502   \u251c\u2500\u2500 test_weighted_prediction.py  # NEW\n\u2502   \u251c\u2500\u2500 test_input_projections.py    # NEW\n\u2502   \u251c\u2500\u2500 test_output_projections.py   # NEW\n\u2502   \u2514\u2500\u2500 test_phase1_integration.py   # NEW\n\u2514\u2500\u2500 examples/\n    \u2514\u2500\u2500 phase1_demo.py        # NEW: Demonstrate new features\n</code></pre>"},{"location":"PHASE1_PLAN/#timeline-estimate","title":"Timeline Estimate","text":"<ul> <li>Step 1 (Weighting): ~30 min</li> <li>Step 2 (Hierarchical): ~1 hour</li> <li>Step 3 (Input Projections): ~1 hour</li> <li>Step 4 (Output Projections): ~1 hour</li> <li>Step 5 (Integration): ~30 min</li> </ul> <p>Total: ~4 hours for Phase 1</p>"},{"location":"PHASE1_PLAN/#notes","title":"Notes","text":"<ul> <li>Keep existing <code>predict()</code> signature for backward compatibility</li> <li>All new parameters should be optional with sensible defaults</li> <li>Maintain test coverage above 90%</li> <li>Document all new public APIs with examples</li> </ul>"},{"location":"REPL_GUIDE/","title":"Infinigram REPL Guide","text":"<p>The Infinigram REPL (Read-Eval-Print Loop) provides an interactive shell for exploring byte-level language models, testing predictions, and training models incrementally.</p>"},{"location":"REPL_GUIDE/#getting-started","title":"Getting Started","text":""},{"location":"REPL_GUIDE/#starting-the-repl","title":"Starting the REPL","text":"<pre><code># From Python\npython -m infinigram.repl\n\n# Or using the entry point script\n./bin/infinigram-repl\n</code></pre> <p>You'll see: <pre><code>======================================================================\n  INFINIGRAM INTERACTIVE REPL\n======================================================================\n\nType '/help' for available commands or '/quit' to exit.\n\ninfinigram&gt;\n</code></pre></p>"},{"location":"REPL_GUIDE/#core-concepts","title":"Core Concepts","text":""},{"location":"REPL_GUIDE/#datasets-models","title":"Datasets = Models","text":"<p>In Infinigram, datasets are models. Each dataset is a trained Infinigram model built from the text you load into it. You can:</p> <ul> <li>Create multiple named datasets</li> <li>Switch between datasets</li> <li>Incrementally add training data</li> <li>Compare predictions across datasets</li> </ul>"},{"location":"REPL_GUIDE/#the-prompt","title":"The Prompt","text":"<p>The prompt shows your current dataset:</p> <pre><code>infinigram&gt;              # No dataset selected\ninfinigram [english]&gt;    # \"english\" dataset is active\n</code></pre>"},{"location":"REPL_GUIDE/#commands","title":"Commands","text":""},{"location":"REPL_GUIDE/#dataset-management","title":"Dataset Management","text":""},{"location":"REPL_GUIDE/#dataset-name-create-or-switch-to-dataset","title":"<code>/dataset &lt;name&gt;</code> - Create or Switch to Dataset","text":"<p>Create a new dataset or switch to an existing one.</p> <pre><code>infinigram&gt; /dataset english\n\u2713 Created dataset: english\n\u2713 Switched to dataset: english\n</code></pre>"},{"location":"REPL_GUIDE/#dataset-copy-source-destination-copy-dataset","title":"<code>/dataset copy &lt;source&gt; &lt;destination&gt;</code> - Copy Dataset","text":"<p>Create a deep copy of an existing dataset with all its data and configuration.</p> <pre><code>infinigram [english]&gt; /dataset copy english english_backup\n\u2713 Copied dataset 'english' to 'english_backup'\n  Size: 1024 bytes\n</code></pre> <p>This is useful for: - Creating backups before augmentation - Experimenting with different projections on the same base data - A/B testing different model configurations</p>"},{"location":"REPL_GUIDE/#datasets-list-all-datasets","title":"<code>/datasets</code> - List All Datasets","text":"<p>See all loaded datasets and their sizes.</p> <pre><code>infinigram [english]&gt; /datasets\nAvailable datasets:\n  english: 1024 bytes (current)\n  spanish: 2048 bytes\n  code: 512 bytes\n</code></pre>"},{"location":"REPL_GUIDE/#use-name-switch-dataset","title":"<code>/use &lt;name&gt;</code> - Switch Dataset","text":"<p>Switch to a different dataset.</p> <pre><code>infinigram [english]&gt; /use spanish\n\u2713 Switched to dataset: spanish\n</code></pre>"},{"location":"REPL_GUIDE/#loading-data","title":"Loading Data","text":""},{"location":"REPL_GUIDE/#load-text-load-text","title":"<code>/load &lt;text&gt;</code> - Load Text","text":"<p>Create a dataset from inline text.</p> <pre><code>infinigram&gt; /dataset demo\ninfinigram [demo]&gt; /load the cat sat on the mat\n\u2713 Loaded into 'demo': 23 bytes\n</code></pre>"},{"location":"REPL_GUIDE/#load-file-path-load-from-file","title":"<code>/load --file &lt;path&gt;</code> - Load from File","text":"<p>Load a text file into the current dataset.</p> <pre><code>infinigram [demo]&gt; /load --file data/shakespeare.txt\nLoaded 1048576 characters from data/shakespeare.txt\n\u2713 Loaded into 'demo': 1048576 bytes\n</code></pre>"},{"location":"REPL_GUIDE/#load-jsonl-path-load-from-jsonl","title":"<code>/load --jsonl &lt;path&gt;</code> - Load from JSONL","text":"<p>Load documents from a JSONL file. Each line should be a JSON object with a <code>text</code> field.</p> <pre><code>infinigram [demo]&gt; /load --jsonl data/documents.jsonl\nLoaded 1000 documents from data/documents.jsonl\n\u2713 Loaded into 'demo': 524288 bytes\n</code></pre> <p>JSONL Format: <pre><code>{\"text\": \"First document content\"}\n{\"text\": \"Second document content\"}\n{\"text\": \"Third document content\"}\n</code></pre></p> <p>Documents are automatically separated with <code>\\n\\n</code> to prevent cross-document patterns.</p> <p>Custom Field: <pre><code>/load --jsonl data.jsonl --field content\n</code></pre></p>"},{"location":"REPL_GUIDE/#incremental-training","title":"Incremental Training","text":""},{"location":"REPL_GUIDE/#add-text-add-text-to-dataset","title":"<code>/add &lt;text&gt;</code> - Add Text to Dataset","text":"<p>Add more training examples to the current dataset.</p> <pre><code>infinigram [demo]&gt; /add the dog sat on the log\n\u2713 Added 23 bytes to 'demo'\n  Total corpus size: 46 bytes\n</code></pre>"},{"location":"REPL_GUIDE/#add-file-path-add-file","title":"<code>/add --file &lt;path&gt;</code> - Add File","text":"<pre><code>infinigram [demo]&gt; /add --file more_data.txt\n\u2713 Added 2048 bytes to 'demo'\n  Total corpus size: 2094 bytes\n</code></pre>"},{"location":"REPL_GUIDE/#add-jsonl-path-add-jsonl","title":"<code>/add --jsonl &lt;path&gt;</code> - Add JSONL","text":"<pre><code>infinigram [demo]&gt; /add --jsonl more_docs.jsonl\nLoaded 100 documents from more_docs.jsonl\n\u2713 Added 51200 bytes to 'demo'\n  Total corpus size: 53294 bytes\n</code></pre>"},{"location":"REPL_GUIDE/#prediction","title":"Prediction","text":""},{"location":"REPL_GUIDE/#predict-text-show-next-byte-probabilities","title":"<code>/predict &lt;text&gt;</code> - Show Next-Byte Probabilities","text":"<p>Display the probability distribution for the next byte.</p> <pre><code>infinigram [demo]&gt; /predict the cat\nContext: 'the cat' (7 bytes)\nTop 50 predictions:\n\n  ' ' (byte 32): 0.853\n  's' (byte 115): 0.042\n  '.' (byte 46): 0.031\n  ...\n</code></pre> <p>Show as bytes: <pre><code>infinigram [demo]&gt; /predict the cat --bytes\nContext: 'the cat' (7 bytes)\nTop 50 predictions:\n\n  Byte  32 (0x20): 0.853\n  Byte 115 (0x73): 0.042\n  Byte  46 (0x2E): 0.031\n  ...\n</code></pre></p>"},{"location":"REPL_GUIDE/#complete-text-generate-completion","title":"<code>/complete &lt;text&gt;</code> - Generate Completion","text":"<p>Generate a continuation of the input text.</p> <pre><code>infinigram [demo]&gt; /complete the cat\nContext: 'the cat'\nGenerating up to 50 bytes...\n\nGenerated: ' sat on the mat. the dog ran on the log.'\n(45 bytes)\n</code></pre> <p>Specify length: <pre><code>infinigram [demo]&gt; /complete the cat --max 20\nGenerated: ' sat on the warm ma'\n(20 bytes)\n</code></pre></p>"},{"location":"REPL_GUIDE/#configuration","title":"Configuration","text":""},{"location":"REPL_GUIDE/#temperature-value-sampling-temperature","title":"<code>/temperature &lt;value&gt;</code> - Sampling Temperature","text":"<p>Control randomness in generation (default: 1.0).</p> <ul> <li>Higher values (&gt;1.0) = more uniform/random</li> <li>Lower values (&lt;1.0) = more peaked/deterministic</li> </ul> <pre><code>infinigram [demo]&gt; /temperature 0.5\n\u2713 Temperature set to 0.5\n\ninfinigram [demo]&gt; /temperature 2.0\n\u2713 Temperature set to 2.0\n</code></pre>"},{"location":"REPL_GUIDE/#top_k-n-top-k-display","title":"<code>/top_k &lt;n&gt;</code> - Top-K Display","text":"<p>Set how many predictions to show (default: 50).</p> <pre><code>infinigram [demo]&gt; /top_k 10\n\u2713 top_k set to 10\n</code></pre>"},{"location":"REPL_GUIDE/#max_length-n-max-suffix-length","title":"<code>/max_length &lt;n&gt;</code> - Max Suffix Length","text":"<p>Limit the maximum suffix length for matching (default: unlimited).</p> <pre><code>infinigram [demo]&gt; /max_length 20\n\u2713 max_length set to 20\n\ninfinigram [demo]&gt; /max_length none\n\u2713 max_length set to unlimited\n</code></pre>"},{"location":"REPL_GUIDE/#weight-function-weight-function","title":"<code>/weight &lt;function&gt;</code> - Weight Function","text":"<p>Enable hierarchical weighted prediction.</p> <p>Options: <code>none</code>, <code>linear</code>, <code>quadratic</code>, <code>exponential</code>, <code>sigmoid</code></p> <pre><code>infinigram [demo]&gt; /weight quadratic\n\u2713 Weight function set to quadratic\n\ninfinigram [demo]&gt; /weight none\n\u2713 Disabled weighted prediction\n</code></pre>"},{"location":"REPL_GUIDE/#config-show-configuration","title":"<code>/config</code> - Show Configuration","text":"<p>Display current settings.</p> <pre><code>infinigram [demo]&gt; /config\nCurrent Configuration:\n  Temperature: 1.0\n  Top-k: 50\n  Max suffix length: unlimited\n  Weight function: none\n  Weighted prediction min_length: 1\n  Weighted prediction max_length: auto\n</code></pre>"},{"location":"REPL_GUIDE/#information","title":"Information","text":""},{"location":"REPL_GUIDE/#info-dataset-information","title":"<code>/info</code> - Dataset Information","text":"<p>Show current dataset details.</p> <pre><code>infinigram [demo]&gt; /info\nDataset: demo\n  Corpus size: 1024 bytes\n  Vocabulary size: 256\n  Max suffix length: unlimited\n  Min count: 1\n  Smoothing: 0.01\n</code></pre>"},{"location":"REPL_GUIDE/#stats-corpus-statistics","title":"<code>/stats</code> - Corpus Statistics","text":"<p>Show byte distribution statistics.</p> <pre><code>infinigram [demo]&gt; /stats\nCorpus Statistics:\n  Total bytes: 1024\n  Unique bytes: 52\n\n  Top 10 most frequent bytes:\n     32 (' '):   156 (15.23%)\n    101 ('e'):   102 (9.96%)\n    116 ('t'):    89 (8.69%)\n    ...\n</code></pre>"},{"location":"REPL_GUIDE/#augmentationprojections","title":"Augmentation/Projections","text":"<p>Augmentations apply transformations to your dataset, creating variants alongside the original data. This is powerful for case-insensitive models, normalization, and data augmentation.</p>"},{"location":"REPL_GUIDE/#augment-projection-projection-apply-projections","title":"<code>/augment &lt;projection&gt; [projection...]</code> - Apply Projections","text":"<p>Apply one or more projections to the current dataset. The original data is preserved, and augmented variants are added.</p> <p>Available projections: - <code>lowercase</code> - Convert text to lowercase - <code>uppercase</code> - Convert text to UPPERCASE - <code>title</code> - Convert Text To Title Case - <code>strip</code> - Remove leading/trailing whitespace</p> <pre><code>infinigram [demo]&gt; /augment lowercase uppercase\nApplying 2 projection(s) to 'demo'...\n\u2713 Applied projections: lowercase, uppercase\n  Original size: 100 bytes\n  Augmented size: 300 bytes\n  Multiplier: 3.00x\n</code></pre> <p>How it works: - Original data: \"Hello World\" - After <code>/augment lowercase uppercase</code>:   - Original: \"Hello World\"   - Lowercase variant: \"hello world\"   - Uppercase variant: \"HELLO WORLD\"</p> <p>This creates a model that can handle multiple case variations.</p>"},{"location":"REPL_GUIDE/#projections-list-active-projections","title":"<code>/projections</code> - List Active Projections","text":"<p>Show which projections have been applied to the current dataset.</p> <pre><code>infinigram [demo]&gt; /projections\nActive projections for 'demo':\n  lowercase\n  uppercase\n</code></pre>"},{"location":"REPL_GUIDE/#projections-available-list-available-projections","title":"<code>/projections --available</code> - List Available Projections","text":"<p>Show all registered projections you can apply.</p> <pre><code>infinigram&gt; /projections --available\nAvailable projections:\n  lowercase\n  strip\n  title\n  uppercase\n</code></pre>"},{"location":"REPL_GUIDE/#bash-commands","title":"Bash Commands","text":""},{"location":"REPL_GUIDE/#command-execute-bash-command","title":"<code>!&lt;command&gt;</code> - Execute Bash Command","text":"<p>Run any bash command from within the REPL. Useful for file operations, checking data, or quick system tasks.</p> <pre><code>infinigram&gt; !ls -lh data/\n-rw-r--r-- 1 user user 1.2M Oct 17 data.txt\n\ninfinigram&gt; !wc -l data/corpus.txt\n10000 data/corpus.txt\n\ninfinigram&gt; !head -3 data/sample.jsonl\n{\"text\": \"First document\"}\n{\"text\": \"Second document\"}\n{\"text\": \"Third document\"}\n</code></pre> <p>Commands run with a 30-second timeout and capture both stdout and stderr.</p>"},{"location":"REPL_GUIDE/#other","title":"Other","text":""},{"location":"REPL_GUIDE/#help-show-help","title":"<code>/help</code> - Show Help","text":"<p>Display all available commands.</p>"},{"location":"REPL_GUIDE/#quit-or-exit-exit-repl","title":"<code>/quit</code> or <code>/exit</code> - Exit REPL","text":"<p>Leave the REPL.</p>"},{"location":"REPL_GUIDE/#reset-delete-current-dataset","title":"<code>/reset</code> - Delete Current Dataset","text":"<p>Remove the current dataset from memory.</p> <pre><code>infinigram [demo]&gt; /reset\n\u2713 Deleted dataset: demo\n</code></pre>"},{"location":"REPL_GUIDE/#example-workflows","title":"Example Workflows","text":""},{"location":"REPL_GUIDE/#dataset-copying-and-augmentation","title":"Dataset Copying and Augmentation","text":"<pre><code># Create a base dataset\n/dataset base\n/load The quick brown fox jumps over the lazy dog.\n\n# Create a copy for experimentation\n/dataset copy base base_augmented\n\n# Apply augmentations to the copy\n/use base_augmented\n/augment lowercase uppercase\n\n# Compare predictions\n/use base\n/predict The quick\n# Only matches exact case\n\n/use base_augmented\n/predict the quick\n# Works! Lowercase variant exists\n\n/predict THE QUICK\n# Also works! Uppercase variant exists\n</code></pre>"},{"location":"REPL_GUIDE/#building-a-multi-domain-model","title":"Building a Multi-Domain Model","text":"<pre><code># Create separate datasets for different domains\n/dataset code\n/load --file python_code.txt\n\n/dataset prose\n/load --file shakespeare.txt\n\n/dataset technical\n/load --jsonl papers.jsonl\n\n# Compare predictions\n/use code\n/predict def fibonacci\n\n/use prose\n/predict To be or not\n\n/use technical\n/predict The algorithm\n</code></pre>"},{"location":"REPL_GUIDE/#incremental-training_1","title":"Incremental Training","text":"<pre><code># Start with base knowledge\n/dataset assistant\n/load Hello! How can I help you today?\n\n# Add more examples as you go\n/add I'm happy to assist with your questions.\n/add Please let me know if you need anything else.\n/add I'll do my best to provide helpful information.\n\n# Test predictions\n/predict How can I\n</code></pre>"},{"location":"REPL_GUIDE/#experimenting-with-weight-functions","title":"Experimenting with Weight Functions","text":"<pre><code>/load the cat sat on the mat. the cat ran.\n\n# Try different weighting schemes\n/weight linear\n/predict the cat\n\n/weight quadratic\n/predict the cat\n\n/weight exponential\n/predict the cat\n</code></pre>"},{"location":"REPL_GUIDE/#loading-from-jsonl","title":"Loading from JSONL","text":"<pre><code># Create a JSONL dataset\n/dataset wiki\n/load --jsonl wikipedia_articles.jsonl\n\n# Add more articles\n/add --jsonl more_articles.jsonl\n\n# Query\n/predict The capital of France\n</code></pre>"},{"location":"REPL_GUIDE/#using-bash-commands","title":"Using Bash Commands","text":"<pre><code># Check data files before loading\n!ls -lh data/\n!wc -l data/corpus.txt\n\n# Preview JSONL structure\n!head -3 data/documents.jsonl\n\n# Load the data\n/dataset docs\n/load --jsonl data/documents.jsonl\n\n# Check system resources\n!free -h\n!df -h\n\n# Quick text processing\n!grep -c \"keyword\" data/corpus.txt\n</code></pre>"},{"location":"REPL_GUIDE/#tips","title":"Tips","text":"<ol> <li>Start Small: Begin with small datasets to understand behavior</li> <li>Multiple Datasets: Create separate datasets for different tasks</li> <li>Incremental Learning: Use <code>/add</code> to grow datasets over time</li> <li>Experiment: Try different temperatures and weight functions</li> <li>Check Stats: Use <code>/stats</code> to understand your corpus composition</li> <li>JSONL for Documents: Use JSONL format for multi-document corpora</li> <li>Copy Before Augmenting: Use <code>/dataset copy</code> to preserve original data before applying projections</li> <li>Bash Integration: Use <code>!command</code> for quick file checks, data inspection, and system tasks</li> <li>Projection Combinations: Apply multiple projections together for comprehensive normalization</li> </ol>"},{"location":"REPL_GUIDE/#advanced-usage","title":"Advanced Usage","text":""},{"location":"REPL_GUIDE/#temperature-effects","title":"Temperature Effects","text":"<pre><code># Deterministic (greedy)\n/temperature 0.1\n/complete the cat\n# Output: \" sat on the mat. the cat sat on the mat.\"\n\n# Balanced\n/temperature 1.0\n/complete the cat\n# Output: \" ran on the log. the dog sat near\"\n\n# Random/Creative\n/temperature 2.0\n/complete the cat\n# Output: \" wobbled through mysterious gardens while\"\n</code></pre>"},{"location":"REPL_GUIDE/#hierarchical-prediction","title":"Hierarchical Prediction","text":"<pre><code># Linear: w(k) = k\n/weight linear\n/predict the\n\n# Quadratic: w(k) = k\u00b2  (strongly favors longer matches)\n/weight quadratic\n/predict the\n\n# Exponential: w(k) = 2^k  (very strongly favors longest)\n/weight exponential\n/predict the\n</code></pre>"},{"location":"REPL_GUIDE/#troubleshooting","title":"Troubleshooting","text":"<p>Problem: \"No dataset selected\" Solution: Create or select a dataset with <code>/dataset &lt;name&gt;</code></p> <p>Problem: Slow predictions on large corpus Solution: Use <code>/max_length</code> to limit suffix search</p> <p>Problem: Repetitive completions Solution: Increase <code>/temperature</code> for more variety</p> <p>Problem: Random/incoherent completions Solution: Decrease <code>/temperature</code> for more focus</p>"},{"location":"REST_API/","title":"Infinigram REST API Documentation","text":"<p>Version: 0.2.0 Status: Production Ready Compatibility: OpenAI API v1</p>"},{"location":"REST_API/#overview","title":"Overview","text":"<p>Infinigram provides an OpenAI-compatible REST API for corpus-based language modeling. The API allows you to: - Generate text completions using variable-length n-gram matching - Manage multiple models simultaneously - Use hierarchical weighted predictions - Get detailed match metadata and confidence scores</p>"},{"location":"REST_API/#quick-start","title":"Quick Start","text":""},{"location":"REST_API/#1-start-the-server","title":"1. Start the Server","text":"<pre><code># Option 1: Use the module directly\npython -m infinigram.server.api\n\n# Option 2: Start server programmatically\nfrom infinigram.server.api import app, model_manager\nimport uvicorn\n\n# Load your models\nmodel_manager.add_model(\"my-model\", corpus=[1,2,3,4,5], max_length=10)\n\n# Start server\nuvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"REST_API/#2-test-the-api","title":"2. Test the API","text":"<pre><code># Check health\ncurl http://localhost:8000/health\n\n# List models\ncurl http://localhost:8000/v1/models\n\n# Generate completion\ncurl -X POST http://localhost:8000/v1/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"demo\",\n    \"prompt\": [2, 3],\n    \"max_tokens\": 5,\n    \"top_k\": 10\n  }'\n</code></pre>"},{"location":"REST_API/#api-endpoints","title":"API Endpoints","text":""},{"location":"REST_API/#core-endpoints","title":"Core Endpoints","text":""},{"location":"REST_API/#get","title":"<code>GET /</code>","text":"<p>Root endpoint with API information.</p> <p>Response: <pre><code>{\n  \"message\": \"Infinigram API\",\n  \"version\": \"0.2.0\",\n  \"endpoints\": {\n    \"completions\": \"/v1/completions\",\n    \"models\": \"/v1/models\"\n  }\n}\n</code></pre></p>"},{"location":"REST_API/#get-health","title":"<code>GET /health</code>","text":"<p>Health check endpoint.</p> <p>Response: <pre><code>{\n  \"status\": \"healthy\",\n  \"models_loaded\": 2\n}\n</code></pre></p>"},{"location":"REST_API/#completion-endpoints","title":"Completion Endpoints","text":""},{"location":"REST_API/#post-v1completions","title":"<code>POST /v1/completions</code>","text":"<p>Create a text completion (OpenAI-compatible).</p> <p>Request Body: <pre><code>{\n  \"model\": \"demo\",              // Required: Model ID\n  \"prompt\": [1, 2, 3],          // Required: List of integer token IDs\n  \"max_tokens\": 10,             // Optional: Maximum tokens to generate (default: 10)\n  \"temperature\": 1.0,           // Optional: Sampling temperature (not yet implemented)\n  \"top_k\": 50,                  // Optional: Return top k predictions (default: 50)\n  \"weight_function\": \"quadratic\", // Optional: \"linear\", \"quadratic\", \"exponential\", \"sigmoid\"\n  \"min_length\": 1,              // Optional: Minimum suffix length for weighted prediction\n  \"max_length\": null,           // Optional: Maximum suffix length\n  \"echo\": false,                // Optional: Echo prompt in response\n  \"logprobs\": 3                 // Optional: Return log probabilities for top N tokens\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"id\": \"cmpl-1760741740364\",\n  \"object\": \"text_completion\",\n  \"created\": 1760741740,\n  \"model\": \"demo\",\n  \"choices\": [\n    {\n      \"text\": \"[4, 2, 3, 5, 6]\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\",\n      \"metadata\": {\n        \"match_position\": 1,\n        \"match_length\": 7,\n        \"confidence\": 0.493,\n        \"tokens\": [4, 2, 3, 5, 6]\n      }\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 2,\n    \"completion_tokens\": 5,\n    \"total_tokens\": 7\n  }\n}\n</code></pre></p> <p>Example with Weighted Prediction: <pre><code>curl -X POST http://localhost:8000/v1/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"demo\",\n    \"prompt\": [2, 3],\n    \"max_tokens\": 3,\n    \"weight_function\": \"quadratic\",\n    \"min_length\": 1,\n    \"max_length\": 5\n  }'\n</code></pre></p> <p>Example with Log Probabilities: <pre><code>curl -X POST http://localhost:8000/v1/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"demo\",\n    \"prompt\": [2, 3],\n    \"max_tokens\": 2,\n    \"logprobs\": 3\n  }'\n</code></pre></p> <p>Response includes detailed probability information: <pre><code>{\n  \"logprobs\": {\n    \"content\": [\n      {\n        \"tokens\": [\"4\", \"5\", \"1\"],\n        \"token_logprobs\": [-0.307, -1.399, -6.014],\n        \"top_logprobs\": {\n          \"4\": -0.307,\n          \"5\": -1.399,\n          \"1\": -6.014\n        }\n      }\n    ]\n  }\n}\n</code></pre></p>"},{"location":"REST_API/#model-management-endpoints","title":"Model Management Endpoints","text":""},{"location":"REST_API/#get-v1models","title":"<code>GET /v1/models</code>","text":"<p>List all available models (OpenAI-compatible).</p> <p>Response: <pre><code>{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"demo\",\n      \"object\": \"model\",\n      \"created\": 1760741705,\n      \"owned_by\": \"infinigram\",\n      \"description\": \"Simple demo model with numeric tokens\",\n      \"corpus_size\": 17,\n      \"vocab_size\": 9,\n      \"max_length\": 10\n    }\n  ]\n}\n</code></pre></p>"},{"location":"REST_API/#get-v1modelsmodel_id","title":"<code>GET /v1/models/{model_id}</code>","text":"<p>Get information about a specific model.</p> <p>Example: <pre><code>curl http://localhost:8000/v1/models/demo\n</code></pre></p> <p>Response: <pre><code>{\n  \"id\": \"demo\",\n  \"object\": \"model\",\n  \"created\": 1760741759,\n  \"owned_by\": \"infinigram\",\n  \"description\": \"Simple demo model with numeric tokens\",\n  \"corpus_size\": 17,\n  \"vocab_size\": 9,\n  \"max_length\": 10\n}\n</code></pre></p>"},{"location":"REST_API/#post-v1modelsload","title":"<code>POST /v1/models/load</code>","text":"<p>Load a new model from a corpus.</p> <p>Request: <pre><code>{\n  \"model_id\": \"my-custom-model\",\n  \"corpus\": [1, 2, 3, 4, 5, 6, 7, 8],\n  \"max_length\": 10,\n  \"description\": \"My custom model description\"\n}\n</code></pre></p> <p>Example: <pre><code>curl -X POST http://localhost:8000/v1/models/load \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model_id\": \"test-model\",\n    \"corpus\": [1,2,3,4,5,2,3,6],\n    \"max_length\": 5,\n    \"description\": \"Test model\"\n  }'\n</code></pre></p> <p>Response: <pre><code>{\n  \"status\": \"loaded\",\n  \"model_id\": \"test-model\"\n}\n</code></pre></p>"},{"location":"REST_API/#delete-v1modelsmodel_id","title":"<code>DELETE /v1/models/{model_id}</code>","text":"<p>Unload a model from memory.</p> <p>Example: <pre><code>curl -X DELETE http://localhost:8000/v1/models/test-model\n</code></pre></p> <p>Response: <pre><code>{\n  \"status\": \"deleted\",\n  \"model_id\": \"test-model\"\n}\n</code></pre></p>"},{"location":"REST_API/#advanced-features","title":"Advanced Features","text":""},{"location":"REST_API/#hierarchical-weighted-prediction","title":"Hierarchical Weighted Prediction","text":"<p>Use multiple suffix lengths with configurable weighting:</p> <pre><code>curl -X POST http://localhost:8000/v1/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"demo\",\n    \"prompt\": [1, 2, 3],\n    \"max_tokens\": 5,\n    \"weight_function\": \"exponential\",\n    \"min_length\": 1,\n    \"max_length\": 10\n  }'\n</code></pre> <p>Available weight functions: - <code>linear</code>: w(k) = k (default) - <code>quadratic</code>: w(k) = k\u00b2 - <code>exponential</code>: w(k) = 2^k - <code>sigmoid</code>: w(k) = 1 / (1 + exp(-k + 5))</p>"},{"location":"REST_API/#metadata-and-confidence","title":"Metadata and Confidence","text":"<p>Every completion includes metadata about the match:</p> <pre><code>{\n  \"metadata\": {\n    \"match_position\": 42,       // Position in corpus where match was found\n    \"match_length\": 5,          // Length of longest matching suffix\n    \"confidence\": 0.78,         // Confidence score (0-1)\n    \"tokens\": [4, 5, 6]        // Raw token IDs generated\n  }\n}\n</code></pre>"},{"location":"REST_API/#integration-examples","title":"Integration Examples","text":""},{"location":"REST_API/#python-client","title":"Python Client","text":"<pre><code>import requests\n\n# Create completion\nresponse = requests.post(\n    \"http://localhost:8000/v1/completions\",\n    json={\n        \"model\": \"demo\",\n        \"prompt\": [1, 2, 3],\n        \"max_tokens\": 10,\n        \"top_k\": 50\n    }\n)\n\nresult = response.json()\nprint(f\"Generated tokens: {result['choices'][0]['metadata']['tokens']}\")\nprint(f\"Confidence: {result['choices'][0]['metadata']['confidence']}\")\n</code></pre>"},{"location":"REST_API/#llm-probability-mixing","title":"LLM Probability Mixing","text":"<p>Use Infinigram to ground LLM predictions in a specific corpus:</p> <pre><code># Get LLM probabilities\nllm_probs = llm_api.get_next_token_probs(context)\n\n# Get Infinigram probabilities\ninfinigram_response = requests.post(\n    \"http://localhost:8000/v1/completions\",\n    json={\"model\": \"domain-corpus\", \"prompt\": context, \"max_tokens\": 1}\n).json()\n\ninfinigram_probs = parse_probs_from_logprobs(infinigram_response)\n\n# Mix probabilities\nmixed_probs = 0.7 * llm_probs + 0.3 * infinigram_probs\nnext_token = sample(mixed_probs)\n</code></pre>"},{"location":"REST_API/#error-handling","title":"Error Handling","text":""},{"location":"REST_API/#model-not-found","title":"Model Not Found","text":"<p><pre><code>{\n  \"detail\": \"Model 'unknown-model' not found. Available models: ['demo', 'large-demo']\"\n}\n</code></pre> HTTP Status: 404</p>"},{"location":"REST_API/#invalid-request","title":"Invalid Request","text":"<p><pre><code>{\n  \"detail\": \"String prompts not yet supported. Please provide a list of integer token IDs.\"\n}\n</code></pre> HTTP Status: 400</p>"},{"location":"REST_API/#unknown-weight-function","title":"Unknown Weight Function","text":"<p><pre><code>{\n  \"detail\": \"Unknown weight function 'invalid'. Available: ['linear', 'quadratic', 'exponential', 'sigmoid']\"\n}\n</code></pre> HTTP Status: 400</p>"},{"location":"REST_API/#performance-characteristics","title":"Performance Characteristics","text":"<ul> <li>Latency: &lt;10ms for typical queries (100-token context)</li> <li>Throughput: 1000+ requests/second on single CPU</li> <li>Memory: O(corpus_size) per model</li> <li>Model loading: Instant (no training required)</li> </ul>"},{"location":"REST_API/#roadmap","title":"Roadmap","text":"<p>Planned enhancements: - [ ] Streaming responses for long completions - [ ] String tokenization (BPE/WordPiece support) - [ ] Authentication and API keys - [ ] Rate limiting - [ ] Batch completion endpoint - [ ] Model persistence to disk - [ ] Prometheus metrics endpoint - [ ] WebSocket support for real-time predictions</p>"},{"location":"REST_API/#see-also","title":"See Also","text":"<ul> <li>Architecture Documentation</li> <li>Phase 1 Implementation Plan</li> <li>API Source Code</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/","title":"Infinigram Package Extraction - COMPLETE \u2705","text":"<p>Date: October 17, 2025 Version: 0.1.0 Status: New independent package created and tested</p>"},{"location":"archive/EXTRACTION_COMPLETE/#summary","title":"Summary","text":"<p>Successfully extracted Infinigram from the LangCalc project into a standalone Python package. The package is fully functional, tested, documented, and ready for independent development.</p>"},{"location":"archive/EXTRACTION_COMPLETE/#what-was-created","title":"What Was Created","text":""},{"location":"archive/EXTRACTION_COMPLETE/#package-structure","title":"Package Structure","text":"<pre><code>infinigram/                           # New independent package\n\u251c\u2500\u2500 README.md                         # Comprehensive documentation (10KB)\n\u251c\u2500\u2500 LICENSE                           # MIT License\n\u251c\u2500\u2500 setup.py                          # Package configuration\n\u251c\u2500\u2500 pytest.ini                        # Test configuration\n\u251c\u2500\u2500 .gitignore                        # Git ignore rules\n\u251c\u2500\u2500 INFINIGRAM_PROJECT.md             # Project overview and roadmap\n\u251c\u2500\u2500 EXTRACTION_COMPLETE.md            # This file\n\u251c\u2500\u2500 infinigram/                       # Main package\n\u2502   \u251c\u2500\u2500 __init__.py                  # Public API\n\u2502   \u251c\u2500\u2500 infinigram.py                # Core implementation (381 lines)\n\u2502   \u2514\u2500\u2500 suffix_array.py              # Suffix array class\n\u251c\u2500\u2500 tests/                            # Test suite\n\u2502   \u2514\u2500\u2500 test_infinigram.py           # 36 tests (all passing)\n\u251c\u2500\u2500 examples/                         # Usage examples\n\u2502   \u2514\u2500\u2500 demo.py                      # Simple demonstration\n\u2514\u2500\u2500 docs/                             # Documentation (to be expanded)\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#files-extracted-from-langcalc","title":"Files Extracted from LangCalc","text":"Source File Destination Lines Description <code>langcalc/infinigram.py</code> <code>infinigram/infinigram.py</code> 381 Core Infinigram class <code>langcalc/data/suffix_array.py</code> <code>infinigram/suffix_array.py</code> ~200 SuffixArray implementation <code>tests/test_unit/test_infinigram.py</code> <code>tests/test_infinigram.py</code> ~500 36 comprehensive tests <code>infinigram_simple_demo.py</code> <code>examples/demo.py</code> ~200 Usage demonstrations"},{"location":"archive/EXTRACTION_COMPLETE/#verification-results","title":"Verification Results","text":""},{"location":"archive/EXTRACTION_COMPLETE/#package-installation","title":"\u2705 Package Installation","text":"<pre><code>$ cd infinigram\n$ pip install -e .\nSuccessfully installed infinigram-0.1.0\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#import-test","title":"\u2705 Import Test","text":"<pre><code>from infinigram import Infinigram\nmodel = Infinigram([1, 2, 3, 4, 2, 3, 5])\nprobs = model.predict([2, 3])\n# Works perfectly!\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#test-suite","title":"\u2705 Test Suite","text":"<pre><code>$ pytest tests/ -v\n================================ 36 passed in 0.33s ===============================\n</code></pre> <p>All tests passing: - 5 suffix array tests - 8 core Infinigram tests - 5 longest suffix tests - 4 continuation tests - 5 prediction tests - 3 confidence tests - 3 update tests - 5 edge case tests - 3 integration tests</p>"},{"location":"archive/EXTRACTION_COMPLETE/#git-repository","title":"\u2705 Git Repository","text":"<pre><code>$ git log --oneline\n7b8fa4a Initial commit: Infinigram v0.1.0 - Variable-length n-gram language model\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#key-features","title":"Key Features","text":""},{"location":"archive/EXTRACTION_COMPLETE/#1-variable-length-n-grams","title":"1. Variable-Length N-grams","text":"<ul> <li>Automatically finds longest matching pattern</li> <li>No need to pre-specify n</li> <li>Uses as much context as available (up to max_length)</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#2-suffix-array-efficiency","title":"2. Suffix Array Efficiency","text":"<ul> <li>O(n log n) construction time</li> <li>O(m log n) query time</li> <li>O(n) space complexity</li> <li>34x more memory efficient than hash-based 5-grams</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#3-complete-api","title":"3. Complete API","text":"<pre><code>from infinigram import Infinigram\n\n# Create model\nmodel = Infinigram(corpus, max_length=20, smoothing=0.01)\n\n# Predict next token\nprobs = model.predict(context, top_k=10)\n\n# Find longest match\nposition, length = model.longest_suffix(context)\n\n# Get confidence score\nconfidence = model.confidence(context)\n\n# Update corpus\nmodel.update(new_tokens)\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#4-well-tested","title":"4. Well-Tested","text":"<ul> <li>36 comprehensive tests</li> <li>100% pass rate</li> <li>Edge cases covered</li> <li>Integration scenarios included</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#5-documented","title":"5. Documented","text":"<ul> <li>Comprehensive README (10KB)</li> <li>API reference</li> <li>Usage examples</li> <li>Project roadmap</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#why-independent-package","title":"Why Independent Package?","text":""},{"location":"archive/EXTRACTION_COMPLETE/#1-focused-development","title":"1. Focused Development","text":"<ul> <li>Can evolve independently of LangCalc</li> <li>Specialized features (compression, incremental updates)</li> <li>Performance optimizations without breaking LangCalc</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#2-broader-applicability","title":"2. Broader Applicability","text":"<ul> <li>Useful beyond compositional modeling</li> <li>Can be integrated into various NLP pipelines</li> <li>Potential for pre-trained models</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#3-clear-api","title":"3. Clear API","text":"<ul> <li>Simple, focused interface</li> <li>No LangCalc dependencies</li> <li>Easy to understand and use</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#4-independent-evolution","title":"4. Independent Evolution","text":"<ul> <li>More parameters can be added</li> <li>Advanced features (projections, transformations)</li> <li>Experimentation without affecting LangCalc</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#integration-options-with-langcalc","title":"Integration Options with LangCalc","text":""},{"location":"archive/EXTRACTION_COMPLETE/#option-1-direct-dependency-recommended","title":"Option 1: Direct Dependency (Recommended)","text":"<pre><code># In langcalc/setup.py\ninstall_requires = [\n    \"infinigram&gt;=0.1.0\",\n    ...\n]\n\n# In langcalc/__init__.py\nfrom infinigram import Infinigram\n\n__all__ = [\n    \"Infinigram\",  # Re-export for convenience\n    ...\n]\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#option-2-optional-dependency","title":"Option 2: Optional Dependency","text":"<pre><code># In langcalc/setup.py\nextras_require = {\n    \"infinigram\": [\"infinigram&gt;=0.1.0\"],\n    ...\n}\n\n# In langcalc code\ntry:\n    from infinigram import Infinigram\nexcept ImportError:\n    # Fallback or raise helpful error\n    raise ImportError(\"Install infinigram: pip install infinigram\")\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#option-3-keep-both-temporary","title":"Option 3: Keep Both (Temporary)","text":"<pre><code># Keep langcalc/infinigram.py for now\n# Gradually migrate to external package\n# Remove after deprecation period\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#next-steps","title":"Next Steps","text":""},{"location":"archive/EXTRACTION_COMPLETE/#immediate-week-1","title":"Immediate (Week 1)","text":"<ul> <li> Extract code from LangCalc</li> <li> Create package structure</li> <li> Set up tests</li> <li> Write documentation</li> <li> Initialize git repository</li> <li> Push to GitHub</li> <li> Set up CI/CD (GitHub Actions)</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#short-term-weeks-2-4","title":"Short-term (Weeks 2-4)","text":"<ul> <li> Add more examples</li> <li> Create API documentation website</li> <li> Write CONTRIBUTING.md</li> <li> Add badges to README</li> <li> Performance benchmarking suite</li> <li> Optimize suffix array construction</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#medium-term-months-2-3","title":"Medium-term (Months 2-3)","text":"<ul> <li> Incremental suffix array updates</li> <li> Compressed suffix arrays</li> <li> Character-level and subword support</li> <li> Integration examples with popular libraries</li> <li> First PyPI release (v0.2.0)</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#long-term-months-4-6","title":"Long-term (Months 4-6)","text":"<ul> <li> Pre-trained models</li> <li> Parallel/distributed implementations</li> <li> GPU acceleration</li> <li> Advanced features (projections, fuzzy matching)</li> <li> Stable v1.0.0 release</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#development-workflow","title":"Development Workflow","text":""},{"location":"archive/EXTRACTION_COMPLETE/#making-changes","title":"Making Changes","text":"<pre><code>cd infinigram\n\n# Make changes to code\nvim infinigram/infinigram.py\n\n# Run tests\npytest tests/\n\n# Check coverage\npytest tests/ --cov=infinigram --cov-report=html\n\n# Commit changes\ngit add .\ngit commit -m \"Description of changes\"\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#testing","title":"Testing","text":"<pre><code># All tests\npytest tests/\n\n# Verbose\npytest tests/ -v\n\n# With coverage\npytest tests/ --cov=infinigram\n\n# Specific test\npytest tests/test_infinigram.py::TestPredict::test_predict_returns_probabilities\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#installation-modes","title":"Installation Modes","text":"<pre><code># Development mode (editable)\npip install -e .\n\n# With development dependencies\npip install -e .[dev]\n\n# Normal installation (when ready)\npip install infinigram\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#performance-characteristics","title":"Performance Characteristics","text":"<p>From initial benchmarks:</p> Corpus Size Construction Prediction Suffix Search 100 tokens 0.07 ms 0.043 ms 0.014 ms 1K tokens 6.09 ms 0.390 ms 0.184 ms 10K tokens 718 ms 4.370 ms 2.373 ms <p>Memory: ~1 GB for 1B token corpus (vs 34 GB for hash-based 5-grams)</p>"},{"location":"archive/EXTRACTION_COMPLETE/#comparison-with-alternatives","title":"Comparison with Alternatives","text":"Feature N-gram (hash) Infinigram Neural LM Training time Seconds Seconds Hours/Days Model size GB (large n) MB GB Query time O(1) O(m log n) O(vocab_size) Pattern length Fixed Variable N/A Memory O(V^n) O(corpus) O(params) Exact matching Yes Yes No"},{"location":"archive/EXTRACTION_COMPLETE/#use-cases","title":"Use Cases","text":""},{"location":"archive/EXTRACTION_COMPLETE/#1-code-completion","title":"1. Code Completion","text":"<pre><code>code_corpus = tokenize_code(\"src/**/*.py\")\nmodel = Infinigram(code_corpus, max_length=50)\nsuggestions = model.predict(tokenize(\"def factorial(n):\"))\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#2-text-autocomplete","title":"2. Text Autocomplete","text":"<pre><code>query_corpus = tokenize_queries(user_queries)\nmodel = Infinigram(query_corpus, max_length=10)\ncompletions = model.predict(tokenize(\"how to\"))\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#3-baseline-lm","title":"3. Baseline LM","text":"<pre><code># Quick baseline for comparison\nbaseline = Infinigram(training_corpus)\nneural_lm_perplexity = evaluate(neural_lm, test_set)\nbaseline_perplexity = evaluate(baseline, test_set)\n</code></pre>"},{"location":"archive/EXTRACTION_COMPLETE/#maintenance","title":"Maintenance","text":""},{"location":"archive/EXTRACTION_COMPLETE/#versioning","title":"Versioning","text":"<ul> <li>0.1.x: Alpha releases, API may change</li> <li>0.x.y: Beta releases, stabilizing API</li> <li>1.x.y: Stable releases, semantic versioning</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#release-checklist","title":"Release Checklist","text":"<ul> <li> All tests passing</li> <li> Documentation updated</li> <li> Version bumped in setup.py and init.py</li> <li> CHANGELOG.md updated</li> <li> Git tag created</li> <li> PyPI package built and uploaded</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#support","title":"Support","text":""},{"location":"archive/EXTRACTION_COMPLETE/#documentation","title":"Documentation","text":"<ul> <li>README.md - Getting started</li> <li>INFINIGRAM_PROJECT.md - Project overview</li> <li>tests/test_infinigram.py - Usage examples</li> <li>examples/demo.py - Live demonstrations</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#getting-help","title":"Getting Help","text":"<ul> <li>GitHub Issues (to be created)</li> <li>Documentation website (to be created)</li> <li>Email: lex@metafunctor.com</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#credits","title":"Credits","text":"<p>Original Development: Part of the LangCalc project Author: Alex Towell (@queelius) License: MIT Status: Independent package as of Oct 17, 2025</p>"},{"location":"archive/EXTRACTION_COMPLETE/#references","title":"References","text":"<ul> <li>LangCalc: https://github.com/queelius/langcalc</li> <li>Suffix Arrays: Manber &amp; Myers (1993)</li> <li>Variable-length n-grams: Various NLP literature</li> </ul>"},{"location":"archive/EXTRACTION_COMPLETE/#extraction-checklist","title":"\u2705 Extraction Checklist","text":"<ul> <li> Create package directory structure</li> <li> Copy core files (infinigram.py, suffix_array.py)</li> <li> Copy test suite (36 tests)</li> <li> Copy examples (demo.py)</li> <li> Create setup.py configuration</li> <li> Create init.py with public API</li> <li> Create README.md documentation</li> <li> Create LICENSE file (MIT)</li> <li> Create .gitignore</li> <li> Create pytest.ini</li> <li> Create project documentation (INFINIGRAM_PROJECT.md)</li> <li> Install package in development mode</li> <li> Verify package imports work</li> <li> Run full test suite (all 36 tests pass)</li> <li> Initialize git repository</li> <li> Create initial commit</li> <li> Push to GitHub (next step)</li> <li> Set up CI/CD (next step)</li> </ul> <p>Status: Infinigram is now an independent, fully functional Python package! \ud83d\ude80</p> <p>Ready for: - Independent development - GitHub publication - PyPI distribution (when ready) - Integration with LangCalc and other projects</p>"},{"location":"archive/INFINIGRAM_PROJECT/","title":"Infinigram Project - Extraction Summary","text":"<p>Date: October 17, 2025 Source: LangCalc project Status: New independent package created</p>"},{"location":"archive/INFINIGRAM_PROJECT/#overview","title":"Overview","text":"<p>Infinigram has been extracted from the LangCalc project into its own standalone package. This allows it to be developed independently while still being usable within LangCalc.</p>"},{"location":"archive/INFINIGRAM_PROJECT/#why-separate-package","title":"Why Separate Package?","text":""},{"location":"archive/INFINIGRAM_PROJECT/#1-independent-value","title":"1. Independent Value","text":"<ul> <li>Infinigram is a complete language model implementation</li> <li>Can be used standalone without any LangCalc dependencies</li> <li>Has broad applicability beyond compositional modeling</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#2-focused-development","title":"2. Focused Development","text":"<ul> <li>Can evolve its own API without affecting LangCalc</li> <li>Easier to add specialized features (incremental updates, compression, etc.)</li> <li>Clear separation of concerns</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#3-reusability","title":"3. Reusability","text":"<ul> <li>Other projects can use Infinigram without LangCalc overhead</li> <li>Can be integrated into various NLP pipelines</li> <li>Potential for pre-trained models and domain-specific variants</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#4-api-flexibility","title":"4. API Flexibility","text":"<ul> <li>Advanced features like projections can be developed independently</li> <li>Parameters and configuration can be expanded</li> <li>Performance optimizations without breaking LangCalc</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#package-structure","title":"Package Structure","text":"<pre><code>infinigram/\n\u251c\u2500\u2500 README.md                   # Comprehensive documentation\n\u251c\u2500\u2500 LICENSE                     # MIT License\n\u251c\u2500\u2500 setup.py                    # Package configuration\n\u251c\u2500\u2500 pytest.ini                  # Test configuration\n\u251c\u2500\u2500 .gitignore                  # Git ignore rules\n\u251c\u2500\u2500 infinigram/                 # Main package\n\u2502   \u251c\u2500\u2500 __init__.py            # Public API\n\u2502   \u251c\u2500\u2500 infinigram.py          # Core Infinigram implementation (381 lines)\n\u2502   \u2514\u2500\u2500 suffix_array.py        # SuffixArray class\n\u251c\u2500\u2500 tests/                      # Test suite\n\u2502   \u2514\u2500\u2500 test_infinigram.py     # 36 comprehensive tests\n\u251c\u2500\u2500 examples/                   # Usage examples\n\u2502   \u2514\u2500\u2500 demo.py                # Simple demo script\n\u2514\u2500\u2500 docs/                       # Documentation\n    \u251c\u2500\u2500 API.md                 # (To be created)\n    \u251c\u2500\u2500 DESIGN.md              # (To be created)\n    \u2514\u2500\u2500 BENCHMARKS.md          # (To be created)\n</code></pre>"},{"location":"archive/INFINIGRAM_PROJECT/#files-extracted","title":"Files Extracted","text":""},{"location":"archive/INFINIGRAM_PROJECT/#core-implementation","title":"Core Implementation","text":"<ol> <li>infinigram/infinigram.py (381 lines)</li> <li>Source: <code>langcalc/infinigram.py</code></li> <li>Core Infinigram class</li> <li>All prediction logic</li> <li>Confidence scoring</li> <li> <p>Dynamic updates</p> </li> <li> <p>infinigram/suffix_array.py</p> </li> <li>Source: <code>langcalc/data/suffix_array.py</code></li> <li>Suffix array construction</li> <li>Binary search implementation</li> <li>Pattern matching</li> </ol>"},{"location":"archive/INFINIGRAM_PROJECT/#tests","title":"Tests","text":"<ol> <li>tests/test_infinigram.py (36 tests)</li> <li>Source: <code>langcalc/tests/test_unit/test_infinigram.py</code></li> <li>Complete test coverage</li> <li>All edge cases</li> <li>Integration scenarios</li> </ol>"},{"location":"archive/INFINIGRAM_PROJECT/#examples","title":"Examples","text":"<ol> <li>examples/demo.py</li> <li>Source: <code>langcalc/infinigram_simple_demo.py</code></li> <li>Simple usage demonstrations</li> <li>Text and numeric examples</li> </ol>"},{"location":"archive/INFINIGRAM_PROJECT/#key-features","title":"Key Features","text":""},{"location":"archive/INFINIGRAM_PROJECT/#variable-length-n-grams","title":"Variable-Length N-grams","text":"<ul> <li>Automatically finds longest matching suffix</li> <li>No need to pre-specify n</li> <li>Uses as much context as available</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#suffix-array-efficiency","title":"Suffix Array Efficiency","text":"<ul> <li>O(n log n) construction</li> <li>O(m log n) query time</li> <li>O(n) space complexity</li> <li>34x more memory efficient than hash-based n-grams</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#confidence-scoring","title":"Confidence Scoring","text":"<ul> <li>Based on match length</li> <li>Ranges from 0.0 to 1.0</li> <li>Higher for longer matches</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#dynamic-updates","title":"Dynamic Updates","text":"<ul> <li>Can add new data to corpus</li> <li>Rebuilds suffix array automatically</li> <li>Predictions reflect new patterns</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#api-design","title":"API Design","text":""},{"location":"archive/INFINIGRAM_PROJECT/#simple-interface","title":"Simple Interface","text":"<pre><code>from infinigram import Infinigram\n\n# Create model\nmodel = Infinigram(corpus, max_length=20)\n\n# Core operations\nprobs = model.predict(context)           # Get probability distribution\npos, len = model.longest_suffix(context) # Find longest match\nconf = model.confidence(context)         # Get confidence score\nmodel.update(new_data)                   # Add new data\n</code></pre>"},{"location":"archive/INFINIGRAM_PROJECT/#parameters","title":"Parameters","text":"<pre><code>Infinigram(\n    corpus: List[int],              # Required: token IDs\n    max_length: Optional[int] = None, # Max pattern length (None = unlimited)\n    min_count: int = 1,              # Min occurrences for pattern\n    smoothing: float = 0.01          # Laplace smoothing factor\n)\n</code></pre>"},{"location":"archive/INFINIGRAM_PROJECT/#testing","title":"Testing","text":""},{"location":"archive/INFINIGRAM_PROJECT/#test-coverage","title":"Test Coverage","text":"<ul> <li>36 tests, all passing</li> <li>Core functionality</li> <li>Edge cases</li> <li>Integration scenarios</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#test-categories","title":"Test Categories","text":"<ol> <li>Suffix Array Tests</li> <li>Construction</li> <li>Pattern matching</li> <li> <p>Edge cases</p> </li> <li> <p>Infinigram Core Tests</p> </li> <li>Initialization</li> <li>Prediction</li> <li> <p>Confidence scoring</p> </li> <li> <p>Integration Tests</p> </li> <li>Text corpus</li> <li>Dynamic updates</li> <li>Large-scale scenarios</li> </ol>"},{"location":"archive/INFINIGRAM_PROJECT/#running-tests","title":"Running Tests","text":"<pre><code># In the infinigram directory\npytest tests/\n\n# With coverage\npytest tests/ --cov=infinigram --cov-report=html\n\n# Verbose\npytest tests/ -v\n</code></pre>"},{"location":"archive/INFINIGRAM_PROJECT/#integration-with-langcalc","title":"Integration with LangCalc","text":""},{"location":"archive/INFINIGRAM_PROJECT/#current-status","title":"Current Status","text":"<ul> <li>Infinigram is still in <code>langcalc/infinigram.py</code></li> <li>LangCalc tests pass with current implementation</li> <li>No breaking changes yet</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#future-integration","title":"Future Integration","text":"<p>Option 1: Direct Dependency <pre><code># In langcalc/setup.py\ninstall_requires = [\n    \"infinigram&gt;=0.1.0\",\n    ...\n]\n\n# In langcalc code\nfrom infinigram import Infinigram\n</code></pre></p> <p>Option 2: Optional Dependency <pre><code># In langcalc/setup.py\nextras_require = {\n    \"infinigram\": [\"infinigram&gt;=0.1.0\"],\n    ...\n}\n\n# In langcalc code\ntry:\n    from infinigram import Infinigram\nexcept ImportError:\n    from langcalc.infinigram import Infinigram  # Fallback\n</code></pre></p> <p>Option 3: Compatibility Layer <pre><code># In langcalc/infinigram.py\nfrom infinigram import Infinigram as _Infinigram\n\nclass Infinigram(_Infinigram):\n    \"\"\"LangCalc-specific wrapper around infinigram.Infinigram\"\"\"\n    # Add LangCalc-specific features if needed\n</code></pre></p>"},{"location":"archive/INFINIGRAM_PROJECT/#development-roadmap","title":"Development Roadmap","text":""},{"location":"archive/INFINIGRAM_PROJECT/#phase-1-core-stability-weeks-1-2","title":"Phase 1: Core Stability (Weeks 1-2)","text":"<ul> <li> Set up independent git repository</li> <li> Verify all tests pass independently</li> <li> Add CI/CD (GitHub Actions)</li> <li> Create comprehensive API documentation</li> <li> Add more examples</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#phase-2-performance-weeks-3-4","title":"Phase 2: Performance (Weeks 3-4)","text":"<ul> <li> Benchmark suite</li> <li> Optimize suffix array construction</li> <li> Implement incremental updates (avoid full rebuild)</li> <li> Memory profiling and optimization</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#phase-3-advanced-features-weeks-5-8","title":"Phase 3: Advanced Features (Weeks 5-8)","text":"<ul> <li> Compressed suffix arrays</li> <li> Parallel construction</li> <li> Streaming corpus support</li> <li> GPU acceleration for batch predictions</li> <li> Character-level and subword tokenization</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#phase-4-distribution-weeks-9-12","title":"Phase 4: Distribution (Weeks 9-12)","text":"<ul> <li> Publish to PyPI</li> <li> Create documentation website</li> <li> Pre-trained models for common domains</li> <li> Integration examples with popular NLP libraries</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#potential-extensions","title":"Potential Extensions","text":""},{"location":"archive/INFINIGRAM_PROJECT/#1-compressed-suffix-arrays","title":"1. Compressed Suffix Arrays","text":"<ul> <li>Reduce memory footprint for very large corpora</li> <li>Trade query time for space</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#2-incremental-updates","title":"2. Incremental Updates","text":"<ul> <li>Avoid full suffix array rebuild on updates</li> <li>Maintain sorted order efficiently</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#3-distributed-suffix-arrays","title":"3. Distributed Suffix Arrays","text":"<ul> <li>Shard corpus across multiple machines</li> <li>Parallel queries</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#4-domain-specific-models","title":"4. Domain-Specific Models","text":"<ul> <li>Pre-trained on code, Wikipedia, books, etc.</li> <li>Fine-tuning capabilities</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#5-advanced-projections","title":"5. Advanced Projections","text":"<ul> <li>Context transformations before matching</li> <li>Semantic similarity-based retrieval</li> <li>Edit distance fuzzy matching</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#comparison-with-alternatives","title":"Comparison with Alternatives","text":""},{"location":"archive/INFINIGRAM_PROJECT/#vs-traditional-n-grams","title":"vs Traditional N-grams","text":"Feature N-gram (hash) Infinigram Memory O(V^n) O(corpus_size) Pattern length Fixed Variable Query time O(1) O(m log n) Updates Fast Slow (rebuild)"},{"location":"archive/INFINIGRAM_PROJECT/#vs-neural-language-models","title":"vs Neural Language Models","text":"Feature Neural LM Infinigram Training time Hours/days Seconds/minutes Model size GB MB Inference GPU optimal CPU sufficient Interpretability Low High Exact matching No Yes"},{"location":"archive/INFINIGRAM_PROJECT/#vs-retrieval-models","title":"vs Retrieval Models","text":"Feature BM25/TF-IDF Infinigram Context usage Term frequency Exact patterns Sequence modeling No Yes Variable length No Yes Probability output No Yes"},{"location":"archive/INFINIGRAM_PROJECT/#use-cases","title":"Use Cases","text":""},{"location":"archive/INFINIGRAM_PROJECT/#1-code-completion","title":"1. Code Completion","text":"<ul> <li>Trained on source code repositories</li> <li>Long context (50+ tokens)</li> <li>Exact pattern matching important</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#2-text-autocomplete","title":"2. Text Autocomplete","text":"<ul> <li>Search queries, email, chat</li> <li>Fast predictions needed</li> <li>Dynamic updates (user history)</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#3-data-augmentation","title":"3. Data Augmentation","text":"<ul> <li>Generate synthetic training data</li> <li>Perplexity-based filtering</li> <li>Domain-specific patterns</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#4-baseline-language-model","title":"4. Baseline Language Model","text":"<ul> <li>Quick prototyping</li> <li>Comparison benchmark</li> <li>No GPU required</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#maintenance-plan","title":"Maintenance Plan","text":""},{"location":"archive/INFINIGRAM_PROJECT/#regular-tasks","title":"Regular Tasks","text":"<ul> <li>Monitor test suite (should stay at 100% pass rate)</li> <li>Review issues and PRs</li> <li>Update dependencies</li> <li>Performance benchmarking</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#versioning-strategy","title":"Versioning Strategy","text":"<ul> <li>Semantic versioning (MAJOR.MINOR.PATCH)</li> <li>0.x.y = Alpha/Beta</li> <li>1.x.y = Stable API</li> <li>Breaking changes = MAJOR bump</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#release-checklist","title":"Release Checklist","text":"<ul> <li> All tests passing</li> <li> Documentation updated</li> <li> CHANGELOG.md updated</li> <li> Version bumped in setup.py and init.py</li> <li> Git tag created</li> <li> PyPI package published</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#references","title":"References","text":""},{"location":"archive/INFINIGRAM_PROJECT/#academic-papers","title":"Academic Papers","text":"<ul> <li>Manber &amp; Myers (1993): \"Suffix arrays: a new method for on-line string searches\"</li> <li>Variable-length n-grams in language modeling</li> <li>Katz backoff for smoothing</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#related-projects","title":"Related Projects","text":"<ul> <li>LangCalc: Parent project for algebraic language model composition</li> <li>FastText: Efficient text classification and representation</li> <li>KenLM: Fast n-gram language model toolkit</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#contributors","title":"Contributors","text":"<ul> <li>Alex Towell (@queelius) - Creator and maintainer</li> </ul>"},{"location":"archive/INFINIGRAM_PROJECT/#license","title":"License","text":"<p>MIT License - see LICENSE file</p> <p>Status: Project structure created, ready for independent development! \ud83d\ude80</p> <p>Next step: Initialize git repository and start development cycle.</p>"},{"location":"development/PRIORITY_TESTS_TO_ADD/","title":"Priority Tests to Add - Action Plan","text":"<p>This document provides concrete, copy-paste-ready test code to immediately improve test coverage for the RecursiveInfinigram system.</p>"},{"location":"development/PRIORITY_TESTS_TO_ADD/#phase-1-critical-coverage-gaps-add-these-first","title":"Phase 1: Critical Coverage Gaps (Add These First)","text":""},{"location":"development/PRIORITY_TESTS_TO_ADD/#file-teststest_recursivepy","title":"File: <code>tests/test_recursive.py</code>","text":"<p>Add these test classes to the existing <code>test_recursive.py</code> file:</p> <pre><code>class TestPredictionCombining:\n    \"\"\"Test prediction combining logic - CRITICAL GAP.\"\"\"\n\n    def test_combine_empty_predictions_returns_empty(self):\n        \"\"\"\n        Given: Empty list of weighted predictions\n        When: Combining predictions\n        Then: Returns empty dictionary\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = RecursiveInfinigram(corpus)\n\n        result = model._combine_predictions([])\n\n        assert result == {}\n        assert isinstance(result, dict)\n\n    def test_combine_single_prediction_normalizes(self):\n        \"\"\"\n        Given: Single prediction with probabilities\n        When: Combining predictions\n        Then: Result is normalized to sum to 1.0\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = RecursiveInfinigram(corpus)\n\n        # Single prediction: 'a' (65) with 0.3, 'b' (66) with 0.7\n        weighted_predictions = [\n            ({65: 0.3, 66: 0.7}, 1.0)\n        ]\n\n        result = model._combine_predictions(weighted_predictions)\n\n        # Should normalize (already normalized in this case)\n        assert abs(sum(result.values()) - 1.0) &lt; 1e-9, \\\n            f\"Expected sum=1.0, got {sum(result.values())}\"\n\n    def test_combine_respects_weights(self):\n        \"\"\"\n        Given: Two predictions with different weights\n        When: Combining predictions\n        Then: Higher weight prediction contributes more\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = RecursiveInfinigram(corpus)\n\n        # Two predictions: high weight for 'A', low weight for 'B'\n        weighted_predictions = [\n            ({65: 1.0}, 0.9),  # 'A' with weight 0.9\n            ({66: 1.0}, 0.1),  # 'B' with weight 0.1\n        ]\n\n        result = model._combine_predictions(weighted_predictions)\n\n        assert 65 in result and 66 in result\n        assert result[65] &gt; result[66], \\\n            f\"Expected A (65) &gt; B (66), got {result[65]} vs {result[66]}\"\n\n    def test_combine_overlapping_predictions_sum(self):\n        \"\"\"\n        Given: Multiple predictions for the same byte\n        When: Combining predictions\n        Then: Probabilities are weighted and summed\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = RecursiveInfinigram(corpus)\n\n        # Both predict 'A' (65) with equal weight\n        weighted_predictions = [\n            ({65: 0.5}, 0.5),\n            ({65: 0.8}, 0.5),\n        ]\n\n        result = model._combine_predictions(weighted_predictions)\n\n        # (0.5*0.5 + 0.8*0.5) / (0.5*0.5 + 0.8*0.5) = 1.0\n        assert 65 in result\n        assert abs(result[65] - 1.0) &lt; 1e-9\n\n    def test_combine_multiple_bytes_multiple_predictions(self):\n        \"\"\"\n        Given: Multiple predictions with multiple bytes each\n        When: Combining predictions\n        Then: All bytes correctly weighted and normalized\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = RecursiveInfinigram(corpus)\n\n        weighted_predictions = [\n            ({65: 0.7, 66: 0.3}, 0.6),  # Weight 0.6\n            ({65: 0.4, 67: 0.6}, 0.4),  # Weight 0.4\n        ]\n\n        result = model._combine_predictions(weighted_predictions)\n\n        # Should have all bytes\n        assert 65 in result  # 'A'\n        assert 66 in result  # 'B'\n        assert 67 in result  # 'C'\n\n        # Should normalize to 1.0\n        total = sum(result.values())\n        assert abs(total - 1.0) &lt; 1e-9, f\"Expected sum=1.0, got {total}\"\n\n        # 'A' appears in both, should have highest probability\n        assert result[65] &gt; result[66]\n        assert result[65] &gt; result[67]\n\n\nclass TestTransformerEdgeCases:\n    \"\"\"Test edge cases in transformers.\"\"\"\n\n    def test_edit_distance_calculation_accuracy(self):\n        \"\"\"\n        Given: Pairs of words with known edit distances\n        When: Calculating Levenshtein distance\n        Then: Returns correct distance\n        \"\"\"\n        transformer = EditDistanceTransformer(max_distance=5)\n\n        # Test known distances\n        test_cases = [\n            (b\"cat\", b\"cat\", 0),      # Identical\n            (b\"cat\", b\"bat\", 1),      # One substitution\n            (b\"cat\", b\"ca\", 1),       # One deletion\n            (b\"cat\", b\"cart\", 1),     # One insertion\n            (b\"kitten\", b\"sitting\", 3),  # Classic example\n            (b\"\", b\"abc\", 3),         # Empty string\n            (b\"abc\", b\"\", 3),         # Empty string\n        ]\n\n        for word1, word2, expected_dist in test_cases:\n            actual_dist = transformer._edit_distance(word1, word2)\n            assert actual_dist == expected_dist, \\\n                f\"Edit distance {word1} \u2192 {word2}: expected {expected_dist}, got {actual_dist}\"\n\n    def test_synonym_transformer_no_prefix_to_transform(self):\n        \"\"\"\n        Given: Context where suffix matches entire context\n        When: Generating transformations\n        Then: Returns empty list (no prefix to transform)\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        transformer = SynonymTransformer()\n\n        # Suffix equals entire context\n        context = b\"sat\"\n        suffix = b\"sat\"\n        positions = [8]  # Position of \"sat\" in corpus\n\n        transformations = transformer.generate_transformations(\n            context=context,\n            suffix=suffix,\n            corpus=corpus,\n            match_positions=positions\n        )\n\n        assert transformations == []\n\n    def test_edit_distance_transformer_no_prefix_to_transform(self):\n        \"\"\"\n        Given: Context where suffix matches entire context\n        When: Generating transformations\n        Then: Returns empty list (no prefix to transform)\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        transformer = EditDistanceTransformer(max_distance=2)\n\n        context = b\"mat\"\n        suffix = b\"mat\"\n        positions = [19]\n\n        transformations = transformer.generate_transformations(\n            context=context,\n            suffix=suffix,\n            corpus=corpus,\n            match_positions=positions\n        )\n\n        assert transformations == []\n\n    def test_case_normalizer_already_lowercase(self):\n        \"\"\"\n        Given: Context that is already lowercase\n        When: Generating transformations\n        Then: Returns empty list (no transformation needed)\n        \"\"\"\n        transformer = CaseNormalizer()\n\n        context = b\"the cat sat\"\n        suffix = b\"sat\"\n        corpus = b\"irrelevant\"\n        match_positions = []\n\n        transformations = transformer.generate_transformations(\n            context=context,\n            suffix=suffix,\n            corpus=corpus,\n            match_positions=match_positions\n        )\n\n        assert transformations == []\n\n\nclass TestRecursiveTransformDepthAndBeam:\n    \"\"\"Test recursive transformation with various depths and beam widths.\"\"\"\n\n    def test_beam_width_one_limits_candidates(self):\n        \"\"\"\n        Given: Beam width of 1\n        When: Generating transformations recursively\n        Then: Only best candidate is explored at each level\n        \"\"\"\n        corpus = b\"the cat sat on the mat. the dog ran fast.\"\n        model = RecursiveInfinigram(corpus)\n\n        context = b\"The Cat\"\n\n        # Beam width = 1 should still work\n        contexts = model._recursive_transform(\n            context=context,\n            depth=0,\n            max_depth=2,\n            seen=set(),\n            beam_width=1\n        )\n\n        # Should have at least original\n        assert len(contexts) &gt;= 1\n\n    def test_large_beam_width_explores_more(self):\n        \"\"\"\n        Given: Large beam width\n        When: Generating transformations recursively\n        Then: More candidates are explored\n        \"\"\"\n        corpus = b\"the cat sat on the mat. the dog ran fast.\"\n        model = RecursiveInfinigram(corpus)\n\n        context = b\"The Cat\"\n\n        # Large beam should explore more\n        contexts = model._recursive_transform(\n            context=context,\n            depth=0,\n            max_depth=2,\n            seen=set(),\n            beam_width=10\n        )\n\n        # Should have original + transformations\n        assert len(contexts) &gt;= 1\n\n    def test_no_matches_returns_only_original(self):\n        \"\"\"\n        Given: Context that has no matches in corpus\n        When: Generating transformations recursively\n        Then: Returns only original context (no transformations possible)\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = RecursiveInfinigram(corpus)\n\n        # Context completely outside corpus vocabulary\n        context = b\"xyz\"\n\n        contexts = model._recursive_transform(\n            context=context,\n            depth=0,\n            max_depth=2,\n            seen=set(),\n            beam_width=5\n        )\n\n        # Should return only original (no matches to transform from)\n        assert len(contexts) == 1\n        assert contexts[0][0] == context\n        assert contexts[0][1] == []\n</code></pre>"},{"location":"development/PRIORITY_TESTS_TO_ADD/#phase-2-integration-tests","title":"Phase 2: Integration Tests","text":""},{"location":"development/PRIORITY_TESTS_TO_ADD/#new-file-teststest_recursive_integrationpy","title":"New File: <code>tests/test_recursive_integration.py</code>","text":"<p>Create this new file with integration tests:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nIntegration tests for RecursiveInfinigram end-to-end workflows.\n\nTests the full pipeline: Context \u2192 Transformers \u2192 Scorer \u2192 Predictor\n\"\"\"\n\nimport pytest\nfrom infinigram.recursive import RecursiveInfinigram, CaseNormalizer, EditDistanceTransformer\nfrom infinigram.scoring import create_conservative_scorer, create_aggressive_scorer\n\n\nclass TestEndToEndPredictionFlow:\n    \"\"\"Test complete prediction flow from context to output.\"\"\"\n\n    def test_case_normalization_enables_prediction(self):\n        \"\"\"\n        Given: Corpus with lowercase text\n        When: Context has uppercase letters\n        Then: Case normalization enables successful prediction\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = RecursiveInfinigram(\n            corpus,\n            transformers=[CaseNormalizer()]\n        )\n\n        # Uppercase context (not in corpus)\n        context = b\"The Cat\"\n\n        probs = model.predict(context, max_depth=2, beam_width=5)\n\n        # Should make some prediction (via case normalization)\n        # Can't guarantee specific prediction, but should not be empty\n        assert isinstance(probs, dict)\n        # If case normalization works, should find match and predict\n\n    def test_prediction_with_explanation_includes_transformations(self):\n        \"\"\"\n        Given: Context requiring transformation\n        When: Predicting with explanation\n        Then: Explanations include transformation details\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = RecursiveInfinigram(corpus)\n\n        context = b\"The Cat\"  # Uppercase\n\n        probs, explanations = model.predict_with_explanation(\n            context,\n            max_depth=2,\n            beam_width=3\n        )\n\n        # Should have explanations\n        assert isinstance(explanations, list)\n        assert len(explanations) &gt; 0\n\n        # Check explanation structure\n        for exp in explanations:\n            assert 'context' in exp\n            assert 'transformations' in exp\n            assert 'match_length' in exp\n            assert 'match_frequency' in exp\n            assert 'weight' in exp\n            assert 'predictions' in exp\n\n            # Weight should be in valid range\n            assert 0.0 &lt;= exp['weight'] &lt;= 1.0\n\n\nclass TestScorerImpactOnPredictions:\n    \"\"\"Test that different scorers affect prediction outcomes.\"\"\"\n\n    def test_conservative_vs_aggressive_scorer_behavior(self):\n        \"\"\"\n        Given: Same corpus and context\n        When: Using conservative vs aggressive scorer\n        Then: Scorers produce different weight distributions\n        \"\"\"\n        corpus = b\"the quick brown fox jumps over the lazy dog\"\n\n        conservative_model = RecursiveInfinigram(\n            corpus,\n            scorer=create_conservative_scorer()\n        )\n\n        aggressive_model = RecursiveInfinigram(\n            corpus,\n            scorer=create_aggressive_scorer()\n        )\n\n        # Context with case difference\n        context = b\"The Quick\"\n\n        _, conservative_explanations = conservative_model.predict_with_explanation(\n            context, max_depth=2\n        )\n\n        _, aggressive_explanations = aggressive_model.predict_with_explanation(\n            context, max_depth=2\n        )\n\n        # Both should generate explanations\n        assert len(conservative_explanations) &gt; 0\n        assert len(aggressive_explanations) &gt; 0\n\n        # Weights should differ between scorers\n        # (Conservative penalizes transformations more)\n        conservative_weights = [exp['weight'] for exp in conservative_explanations]\n        aggressive_weights = [exp['weight'] for exp in aggressive_explanations]\n\n        # At least check they computed weights\n        assert all(w &gt;= 0 for w in conservative_weights)\n        assert all(w &gt;= 0 for w in aggressive_weights)\n\n\nclass TestTransformationChaining:\n    \"\"\"Test multiple transformations in sequence.\"\"\"\n\n    def test_multiple_transformations_tracked_in_explanation(self):\n        \"\"\"\n        Given: Context requiring multiple transformations\n        When: Recursing with max_depth &gt; 1\n        Then: Explanation shows chain of transformations\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = RecursiveInfinigram(corpus)\n\n        context = b\"The Dog\"  # Both case and word difference\n\n        probs, explanations = model.predict_with_explanation(\n            context,\n            max_depth=3,  # Allow chaining\n            beam_width=5\n        )\n\n        # Should have explanations with varying transformation depths\n        assert len(explanations) &gt; 0\n\n        # Check if any explanation has multiple transformations\n        has_chain = any(len(exp['transformations']) &gt; 1 for exp in explanations)\n\n        # Check transformation list structure\n        for exp in explanations:\n            assert isinstance(exp['transformations'], list)\n            for transform_desc in exp['transformations']:\n                assert isinstance(transform_desc, str)\n</code></pre>"},{"location":"development/PRIORITY_TESTS_TO_ADD/#phase-3-robustness-and-error-handling","title":"Phase 3: Robustness and Error Handling","text":""},{"location":"development/PRIORITY_TESTS_TO_ADD/#add-to-teststest_recursivepy","title":"Add to <code>tests/test_recursive.py</code>:","text":"<pre><code>class TestRecursiveInfinigramRobustness:\n    \"\"\"Test robustness and error handling.\"\"\"\n\n    def test_empty_corpus_initialization(self):\n        \"\"\"\n        Given: Empty corpus\n        When: Initializing RecursiveInfinigram\n        Then: Initializes without crashing (may have no predictions)\n        \"\"\"\n        corpus = b\"\"\n\n        # Should not crash\n        model = RecursiveInfinigram(corpus)\n\n        assert model.corpus == corpus\n        assert model.model is not None\n\n    def test_empty_context_prediction(self):\n        \"\"\"\n        Given: Empty context\n        When: Making prediction\n        Then: Returns empty dict (no context to match)\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = RecursiveInfinigram(corpus)\n\n        context = b\"\"\n\n        probs = model.predict(context, max_depth=1)\n\n        # Should return dict (possibly empty)\n        assert isinstance(probs, dict)\n\n    def test_context_longer_than_corpus(self):\n        \"\"\"\n        Given: Context longer than entire corpus\n        When: Making prediction\n        Then: Handles gracefully (no match expected)\n        \"\"\"\n        corpus = b\"cat\"\n        model = RecursiveInfinigram(corpus)\n\n        context = b\"the quick brown fox jumps over the lazy dog\"\n\n        probs = model.predict(context, max_depth=1)\n\n        # Should return dict (likely empty)\n        assert isinstance(probs, dict)\n\n    def test_unicode_handling_in_corpus(self):\n        \"\"\"\n        Given: Corpus with UTF-8 characters\n        When: Making predictions\n        Then: Handles unicode correctly\n        \"\"\"\n        corpus = \"the caf\u00e9 is open\".encode('utf-8')\n        model = RecursiveInfinigram(corpus)\n\n        context = \"the caf\u00e9\".encode('utf-8')\n\n        probs = model.predict(context, max_depth=1)\n\n        assert isinstance(probs, dict)\n\n    def test_very_deep_recursion_does_not_crash(self):\n        \"\"\"\n        Given: Very deep max_depth\n        When: Making prediction\n        Then: Does not cause stack overflow\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = RecursiveInfinigram(corpus)\n\n        context = b\"The Cat\"\n\n        # Very deep recursion (should be stopped by max_depth)\n        probs = model.predict(context, max_depth=10, beam_width=2)\n\n        assert isinstance(probs, dict)\n</code></pre>"},{"location":"development/PRIORITY_TESTS_TO_ADD/#phase-4-fill-evaluation-coverage-gaps","title":"Phase 4: Fill Evaluation Coverage Gaps","text":""},{"location":"development/PRIORITY_TESTS_TO_ADD/#add-to-teststest_evaluationpy","title":"Add to <code>tests/test_evaluation.py</code>:","text":"<pre><code>class TestEvaluatorEdgeCases:\n    \"\"\"Test evaluator edge cases for full coverage.\"\"\"\n\n    def test_evaluate_with_verbose_output(self):\n        \"\"\"\n        Given: Test data with multiple samples\n        When: Evaluating with verbose=True\n        Then: Prints progress messages (covers logging lines)\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n        model = Infinigram(corpus)\n        evaluator = Evaluator(model, \"Test\")\n\n        # Create 100 samples to trigger progress printing\n        test_data = [(b\"the\", b\" \")] * 100\n\n        # Should print progress without crashing\n        metrics, results = evaluator.evaluate(test_data, top_k=5, verbose=True)\n\n        assert len(results) == 100\n        assert isinstance(metrics, EvaluationMetrics)\n\n    def test_evaluate_with_no_predictions(self):\n        \"\"\"\n        Given: Model that never returns predictions\n        When: Evaluating\n        Then: Handles gracefully with inf perplexity\n        \"\"\"\n        # Mock model that always returns empty dict\n        class NoOpModel:\n            def predict(self, context, top_k=10):\n                return {}\n\n        model = NoOpModel()\n        evaluator = Evaluator(model, \"NoOp\")\n\n        test_data = [(b\"test\", b\"x\"), (b\"data\", b\"y\")]\n\n        metrics, results = evaluator.evaluate(test_data, top_k=5)\n\n        # Coverage should be 0%\n        assert metrics.coverage == 0.0\n\n        # Perplexity should be infinity (no predictions)\n        assert metrics.perplexity == float('inf')\n\n        # Mean probability should be 0\n        assert metrics.mean_probability == 0.0\n\n        # All predictions should be None\n        assert all(r.predicted is None for r in results)\n\n\nclass TestBenchmarkSuiteVerbose:\n    \"\"\"Test benchmark suite with verbose output.\"\"\"\n\n    def test_compare_models_with_verbose(self):\n        \"\"\"\n        Given: Multiple models and datasets\n        When: Comparing with verbose=True\n        Then: Prints comparison info (covers logging lines)\n        \"\"\"\n        corpus = b\"the cat sat on the mat\"\n\n        models = {\n            \"Vanilla\": Infinigram(corpus),\n            \"Recursive\": RecursiveInfinigram(corpus),\n        }\n\n        suite = BenchmarkSuite(corpus)\n        test_data = suite.create_in_distribution_test(10, 5)\n\n        test_datasets = {\n            \"Test\": test_data,\n        }\n\n        # Should print verbose output\n        results = suite.compare_models(\n            models=models,\n            test_datasets=test_datasets,\n            top_k=5,\n            verbose=True  # Enable verbose logging\n        )\n\n        assert \"Vanilla\" in results\n        assert \"Recursive\" in results\n</code></pre>"},{"location":"development/PRIORITY_TESTS_TO_ADD/#test-execution-plan","title":"Test Execution Plan","text":""},{"location":"development/PRIORITY_TESTS_TO_ADD/#step-1-add-phase-1-tests-critical","title":"Step 1: Add Phase 1 Tests (Critical)","text":"<pre><code># Add the TestPredictionCombining class to test_recursive.py\n# Add the TestTransformerEdgeCases class to test_recursive.py\n# Add the TestRecursiveTransformDepthAndBeam class to test_recursive.py\n\n# Run tests\npython -m pytest tests/test_recursive.py -v\n\n# Check coverage improvement\npython -m pytest tests/test_recursive.py --cov=infinigram.recursive --cov-report=term\n</code></pre> <p>Expected Coverage Improvement: 41% \u2192 ~60%</p>"},{"location":"development/PRIORITY_TESTS_TO_ADD/#step-2-add-phase-2-tests-integration","title":"Step 2: Add Phase 2 Tests (Integration)","text":"<pre><code># Create tests/test_recursive_integration.py with integration tests\n\n# Run integration tests\npython -m pytest tests/test_recursive_integration.py -v\n\n# Check full coverage\npython -m pytest tests/test_recursive*.py --cov=infinigram.recursive --cov-report=term\n</code></pre> <p>Expected Coverage Improvement: ~60% \u2192 ~75%</p>"},{"location":"development/PRIORITY_TESTS_TO_ADD/#step-3-add-phase-3-tests-robustness","title":"Step 3: Add Phase 3 Tests (Robustness)","text":"<pre><code># Add TestRecursiveInfinigramRobustness to test_recursive.py\n\n# Run all recursive tests\npython -m pytest tests/test_recursive*.py -v\n\n# Final coverage check\npython -m pytest tests/test_recursive*.py --cov=infinigram.recursive --cov-report=term\n</code></pre> <p>Expected Coverage Improvement: ~75% \u2192 ~85%</p>"},{"location":"development/PRIORITY_TESTS_TO_ADD/#step-4-add-phase-4-tests-evaluation-gaps","title":"Step 4: Add Phase 4 Tests (Evaluation gaps)","text":"<pre><code># Add edge case tests to test_evaluation.py\n\n# Run evaluation tests\npython -m pytest tests/test_evaluation.py -v\n\n# Check coverage\npython -m pytest tests/test_evaluation.py --cov=infinigram.evaluation --cov-report=term\n</code></pre> <p>Expected Coverage Improvement: 93% \u2192 98%</p>"},{"location":"development/PRIORITY_TESTS_TO_ADD/#success-criteria","title":"Success Criteria","text":"<p>After adding all Phase 1-4 tests:</p> <ul> <li>\u2705 <code>infinigram/recursive.py</code>: 85%+ coverage (up from 41%)</li> <li>\u2705 <code>infinigram/evaluation.py</code>: 98%+ coverage (up from 93%)</li> <li>\u2705 <code>infinigram/scoring.py</code>: 100% coverage (maintained)</li> <li>\u2705 All tests pass</li> <li>\u2705 No implementation changes needed (tests verify existing behavior)</li> </ul>"},{"location":"development/PRIORITY_TESTS_TO_ADD/#notes-on-test-philosophy","title":"Notes on Test Philosophy","text":"<p>These tests follow TDD best practices:</p> <ol> <li>Test Behavior, Not Implementation</li> <li>Focus on observable outcomes (predictions, scores, transformations)</li> <li> <p>Don't test internal data structures unless they're part of the contract</p> </li> <li> <p>Clear Given-When-Then Structure</p> </li> <li>Each test has clear setup, action, and assertion</li> <li> <p>Test names describe the behavior being tested</p> </li> <li> <p>Independent Tests</p> </li> <li>Each test can run in any order</li> <li>No shared state between tests</li> <li> <p>Fresh model instances per test</p> </li> <li> <p>Focused Assertions</p> </li> <li>Each test verifies one behavior</li> <li>Assertions have helpful error messages</li> <li> <p>Edge cases are explicit</p> </li> <li> <p>Resilient to Refactoring</p> </li> <li>Tests will pass even if internal implementation changes</li> <li>Only break if actual behavior changes</li> <li>Enable confident refactoring</li> </ol>"},{"location":"development/TEST_REVIEW_SUMMARY/","title":"Test Strategy Review - Executive Summary","text":"<p>Project: Infinigram RecursiveInfinigram System Date: 2025-10-22 Reviewer: Claude Code (TDD Expert System)</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#overall-assessment-good-with-critical-gaps","title":"Overall Assessment: GOOD with Critical Gaps","text":""},{"location":"development/TEST_REVIEW_SUMMARY/#coverage-summary","title":"Coverage Summary","text":"Module Coverage Status Priority <code>scoring.py</code> 100% \u2705 Excellent Maintain <code>evaluation.py</code> 93% \u2705 Very Good Low <code>recursive.py</code> 41% \u26a0\ufe0f Needs Work HIGH"},{"location":"development/TEST_REVIEW_SUMMARY/#test-suite-quality-710","title":"Test Suite Quality: 7/10","text":"<p>Strengths: - Exemplary behavioral testing in scoring module - Strong mathematical property verification - Good test organization and naming - Minimal implementation coupling</p> <p>Weaknesses: - Core transformation logic largely untested - Integration paths incomplete - Edge case coverage insufficient - 41% coverage in most critical module</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#key-findings","title":"Key Findings","text":""},{"location":"development/TEST_REVIEW_SUMMARY/#whats-working-exceptionally-well","title":"\ud83c\udfaf What's Working Exceptionally Well","text":"<p>1. Scoring Module Tests (100% coverage) <pre><code># Example of excellent behavioral test\ndef test_longer_match_higher_score(self):\n    \"\"\"Longer matches should score higher.\"\"\"\n    score_long = scorer.score(..., match_length=15, ...)\n    score_short = scorer.score(..., match_length=5, ...)\n    assert score_long &gt; score_short  # Tests behavior, not implementation\n</code></pre></p> <p>This is textbook TDD: - Tests the contract (\"longer matches score higher\") - Would pass even if scoring algorithm completely changed - Clear, focused assertion - Enables fearless refactoring</p> <p>2. Evaluation Framework Tests (93% coverage) - Comprehensive end-to-end evaluation flow - Metrics calculation verified - Model comparison framework tested - Only missing: verbose logging and edge cases</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#what-needs-immediate-attention","title":"\u26a0\ufe0f What Needs Immediate Attention","text":"<p>1. RecursiveInfinigram Core Logic (41% coverage)</p> <p>Untested Critical Paths: - \u274c <code>SynonymTransformer.generate_transformations()</code> - Core OOD handling - \u274c <code>EditDistanceTransformer.generate_transformations()</code> - Typo correction - \u274c <code>_combine_predictions()</code> - Weighted prediction merging - \u274c Corpus inspection logic - How transformations are discovered - \u274c Word replacement in context - Transformation application</p> <p>Risk: - Core innovation (OOD generalization) is largely untested - Refactoring would be dangerous - Bugs could hide in untested paths</p> <p>2. Integration Paths</p> <p>Missing end-to-end tests for: - Context \u2192 Transformer \u2192 Scorer \u2192 Predictor flow - Conservative vs Aggressive scorer impact - Multiple transformations in sequence - Transformation explanation generation</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#immediate-action-items","title":"Immediate Action Items","text":""},{"location":"development/TEST_REVIEW_SUMMARY/#priority-1-critical-tests-add-in-next-2-days","title":"Priority 1: Critical Tests (Add in next 2 days)","text":"<p>Test prediction combining: <pre><code>def test_combine_overlapping_predictions_sum(self):\n    \"\"\"Multiple predictions for same byte are correctly weighted.\"\"\"\n    weighted_predictions = [\n        ({65: 0.5}, 0.5),\n        ({65: 0.8}, 0.5),\n    ]\n    result = model._combine_predictions(weighted_predictions)\n    # Should combine: (0.5*0.5 + 0.8*0.5) = 0.65, normalized to 1.0\n</code></pre></p> <p>Test edit distance accuracy: <pre><code>def test_edit_distance_calculation_is_accurate(self):\n    \"\"\"Levenshtein distance calculation matches expected values.\"\"\"\n    assert transformer._edit_distance(b\"cat\", b\"cat\") == 0\n    assert transformer._edit_distance(b\"cat\", b\"bat\") == 1\n    assert transformer._edit_distance(b\"kitten\", b\"sitting\") == 3\n</code></pre></p> <p>Expected Impact: Coverage 41% \u2192 60%</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#priority-2-integration-tests-add-in-next-week","title":"Priority 2: Integration Tests (Add in next week)","text":"<p>Create <code>tests/test_recursive_integration.py</code>: - End-to-end typo correction \u2192 prediction - End-to-end synonym handling \u2192 prediction - Scorer impact on transformation selection</p> <p>Expected Impact: Coverage 60% \u2192 75%</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#priority-3-robustness-add-in-next-2-weeks","title":"Priority 3: Robustness (Add in next 2 weeks)","text":"<ul> <li>Empty corpus/context edge cases</li> <li>Unicode handling</li> <li>Very deep recursion</li> <li>Large beam widths</li> </ul> <p>Expected Impact: Coverage 75% \u2192 85%</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#test-quality-comparison","title":"Test Quality Comparison","text":""},{"location":"development/TEST_REVIEW_SUMMARY/#excellent-example-from-test_scoringpy","title":"Excellent Example (from <code>test_scoring.py</code>)","text":"<pre><code>def test_fewer_transformations_higher_score(self):\n    \"\"\"Fewer transformations should score higher.\"\"\"\n\n    # No transformations (original)\n    score_original = scorer.score(transformations=[])\n\n    # One transformation\n    score_one = scorer.score(transformations=[\"synonym:quick-&gt;fast\"])\n\n    # Multiple transformations\n    score_multi = scorer.score(\n        transformations=[\"synonym:quick-&gt;fast\", \"typo:fox-&gt;foks\"]\n    )\n\n    assert score_original &gt; score_one &gt; score_multi\n</code></pre> <p>Why this is excellent: - \u2705 Tests observable behavior (scoring order) - \u2705 Would pass even if scoring formula changed - \u2705 Clear property being tested - \u2705 Self-documenting test name - \u2705 Enables refactoring with confidence</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#weak-example-from-test_recursivepy","title":"Weak Example (from <code>test_recursive.py</code>)","text":"<pre><code>def test_edit_distance_transformer(self):\n    \"\"\"Test edit distance / typo correction.\"\"\"\n    transformer = EditDistanceTransformer(max_distance=2)\n\n    transformations = transformer.generate_transformations(...)\n\n    # Should work without errors\n    assert isinstance(transformations, list)  # \u26a0\ufe0f Too weak!\n</code></pre> <p>Why this needs improvement: - \u274c Only checks type, not behavior - \u274c Doesn't verify transformations are correct - \u274c Doesn't test max_distance is respected - \u274c Doesn't test edit distance calculation - \u274c Comment admits test is incomplete</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#coverage-goals","title":"Coverage Goals","text":""},{"location":"development/TEST_REVIEW_SUMMARY/#3-month-plan","title":"3-Month Plan","text":"Milestone Timeline Target Coverage Key Additions Phase 1 Week 1 recursive: 60% Prediction combining, edit distance Phase 2 Week 2-3 recursive: 75% Integration tests, end-to-end flows Phase 3 Week 4-6 recursive: 85% Robustness, edge cases Phase 4 Week 7-12 recursive: 85%+ Property-based tests, stress tests"},{"location":"development/TEST_REVIEW_SUMMARY/#target-final-state","title":"Target Final State","text":"<pre><code>infinigram/\n\u251c\u2500\u2500 scoring.py         100% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 (maintain)\n\u251c\u2500\u2500 evaluation.py       98% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2593 (small gap fixes)\n\u2514\u2500\u2500 recursive.py        85% \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591 (major improvement)\n</code></pre>"},{"location":"development/TEST_REVIEW_SUMMARY/#test-organization-recommendation","title":"Test Organization Recommendation","text":""},{"location":"development/TEST_REVIEW_SUMMARY/#current-structure","title":"Current Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 test_recursive.py (10 tests) - Basic only\n\u251c\u2500\u2500 test_scoring.py (33 tests) - Excellent\n\u251c\u2500\u2500 test_evaluation.py (20 tests) - Very good\n\u2514\u2500\u2500 test_*_integration.py (failing due to numpy)\n</code></pre>"},{"location":"development/TEST_REVIEW_SUMMARY/#recommended-structure","title":"Recommended Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 test_recursive.py            # Keep: Core RecursiveInfinigram tests\n\u251c\u2500\u2500 test_transformers.py          # NEW: Dedicated transformer tests\n\u251c\u2500\u2500 test_recursive_integration.py # NEW: End-to-end workflows\n\u251c\u2500\u2500 test_scoring.py              # Keep: Already excellent\n\u251c\u2500\u2500 test_evaluation.py           # Keep: Already good\n\u2514\u2500\u2500 test_edge_cases.py           # NEW: Robustness tests\n</code></pre>"},{"location":"development/TEST_REVIEW_SUMMARY/#concrete-next-steps","title":"Concrete Next Steps","text":""},{"location":"development/TEST_REVIEW_SUMMARY/#this-week","title":"This Week","text":"<ol> <li>Add <code>TestPredictionCombining</code> class to <code>test_recursive.py</code> (5 tests)</li> <li>Add <code>TestTransformerEdgeCases</code> class to <code>test_recursive.py</code> (7 tests)</li> <li>Add <code>TestRecursiveTransformDepthAndBeam</code> class (3 tests)</li> </ol> <p>Files Changed: 1 (<code>tests/test_recursive.py</code>) Lines Added: ~200 Coverage Gain: 41% \u2192 60% (+19%)</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#next-week","title":"Next Week","text":"<ol> <li>Create <code>tests/test_recursive_integration.py</code> (10-15 tests)</li> <li>Add end-to-end transformation \u2192 prediction tests</li> <li>Add scorer integration tests</li> </ol> <p>Files Changed: 1 new file Lines Added: ~300 Coverage Gain: 60% \u2192 75% (+15%)</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#next-two-weeks","title":"Next Two Weeks","text":"<ol> <li>Add robustness tests to <code>test_recursive.py</code> (10 tests)</li> <li>Fix remaining evaluation.py gaps (2 tests)</li> <li>Add property-based tests with Hypothesis (optional)</li> </ol> <p>Files Changed: 2 (<code>test_recursive.py</code>, <code>test_evaluation.py</code>) Lines Added: ~200 Coverage Gain: 75% \u2192 85% (+10%), eval: 93% \u2192 98%</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#risk-assessment","title":"Risk Assessment","text":""},{"location":"development/TEST_REVIEW_SUMMARY/#high-risk-current-state","title":"High Risk (Current State)","text":"<ul> <li>Core transformation logic untested (41% coverage)</li> <li>Refactoring recursive.py would be dangerous</li> <li>Bug fixes lack safety net</li> <li>OOD generalization (main innovation) not verified by tests</li> </ul>"},{"location":"development/TEST_REVIEW_SUMMARY/#low-risk-after-improvements","title":"Low Risk (After Improvements)","text":"<ul> <li>85% coverage provides good safety net</li> <li>Core logic paths verified</li> <li>Integration flows tested</li> <li>Edge cases covered</li> <li>Confident refactoring enabled</li> </ul>"},{"location":"development/TEST_REVIEW_SUMMARY/#conclusion","title":"Conclusion","text":"<p>The Infinigram test suite shows strong TDD practices in scoring and evaluation, but critical gaps in the recursive transformation system. The good news: the existing test structure is sound and can easily accommodate the needed improvements.</p> <p>Key Insight: The scoring module tests are an excellent template. Applying the same behavioral testing approach to the recursive module will bring the entire codebase to production-ready test quality.</p> <p>Recommendation: Prioritize recursive.py test additions immediately. The 41% coverage represents untested core innovation (OOD handling). Adding 15-20 focused tests in the next week will dramatically improve confidence in the system.</p>"},{"location":"development/TEST_REVIEW_SUMMARY/#documentation-provided","title":"Documentation Provided","text":"<ol> <li>TEST_STRATEGY_REVIEW.md - Comprehensive 5000+ word analysis</li> <li>PRIORITY_TESTS_TO_ADD.md - Copy-paste-ready test code</li> <li>TEST_REVIEW_SUMMARY.md (this file) - Executive summary</li> </ol> <p>All test additions can be made without changing implementation code. Tests verify existing behavior and will enable confident future refactoring.</p>"},{"location":"development/TEST_STRATEGY_REVIEW/","title":"Test Strategy Review: Infinigram RecursiveInfinigram System","text":"<p>Date: 2025-10-22 Modules Reviewed: <code>infinigram/recursive.py</code>, <code>infinigram/scoring.py</code>, <code>infinigram/evaluation.py</code> Current Test Coverage: - <code>scoring.py</code>: 100% (82/82 statements) \u2705 - <code>evaluation.py</code>: 93% (186/201 statements) \u2705 - <code>recursive.py</code>: 41% (110/271 statements) \u26a0\ufe0f</p>"},{"location":"development/TEST_STRATEGY_REVIEW/#executive-summary","title":"Executive Summary","text":"<p>The test suite demonstrates excellent behavioral testing for the scoring and evaluation components (100% and 93% coverage respectively), with well-structured tests that focus on contracts rather than implementation. However, the recursive transformation system has significant coverage gaps (41%), particularly around the core transformation generation logic and edge case handling.</p>"},{"location":"development/TEST_STRATEGY_REVIEW/#key-strengths","title":"Key Strengths","text":"<ol> <li>Scoring tests are exemplary - Full coverage with focused, behavioral tests</li> <li>Strong property-based assertions - Tests verify mathematical properties (monotonicity, ranges, etc.)</li> <li>Good separation of concerns - Component tests are isolated and clear</li> <li>Minimal implementation coupling - Tests focus on observable behaviors</li> </ol>"},{"location":"development/TEST_STRATEGY_REVIEW/#critical-gaps","title":"Critical Gaps","text":"<ol> <li>SynonymTransformer core logic untested - Only 41% coverage in recursive.py</li> <li>EditDistanceTransformer transformation generation - Core algorithm not exercised</li> <li>Edge cases in prediction combining - Empty predictions, weight normalization</li> <li>Integration paths incomplete - Transformer \u2192 Scorer \u2192 Predictor flow not fully tested</li> <li>Error handling paths - Unicode errors, corpus size edge cases</li> </ol>"},{"location":"development/TEST_STRATEGY_REVIEW/#detailed-analysis-by-module","title":"Detailed Analysis by Module","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#1-scoring-module-infinigramscoringpy-100-coverage","title":"1. Scoring Module (<code>infinigram/scoring.py</code>) - 100% Coverage \u2705","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#test-quality-excellent","title":"Test Quality: EXCELLENT","text":"<p>What's Working Well: - Comprehensive component testing - Each scoring component tested in isolation - Mathematical properties verified - Ranges, monotonicity, scaling behavior - Edge cases covered - Zero values, empty inputs, boundary conditions - Factory pattern tested - Default, conservative, aggressive scorer variants - Adaptive scorer - Performance tracking and analysis tested</p> <p>Test Structure: <pre><code>TestTransformationScorer (10 tests)\n\u251c\u2500\u2500 Behavioral properties (score ranges, ordering)\n\u251c\u2500\u2500 Component interactions (combining scores)\n\u2514\u2500\u2500 Edge cases (zero length, empty matches)\n\nTestMatchLengthScoring (4 tests)\nTestMatchFrequencyScoring (4 tests)\nTestTransformationQualityScoring (5 tests)\nTestDepthScoring (4 tests)\nTestAdaptiveScorer (3 tests)\nTestScorerFactories (4 tests)\n</code></pre></p> <p>Excellent Examples: <pre><code>def test_longer_match_higher_score(self):\n    \"\"\"Longer matches should score higher.\"\"\"\n    # Tests the BEHAVIOR: longer matches \u2192 higher scores\n    # NOT testing HOW the score is calculated\n    assert score_long &gt; score_short\n\ndef test_sqrt_scaling(self):\n    \"\"\"Should use sqrt for diminishing returns.\"\"\"\n    # Tests a CONTRACT: the scaling function must be sqrt\n    # This is a specification, not implementation detail\n    score = scorer._score_match_length(match_length=50, context_length=100)\n    expected = math.sqrt(0.5)\n    assert abs(score - expected) &lt; 1e-6\n</code></pre></p> <p>No Gaps Identified - This module's tests are a model for the rest of the codebase.</p>"},{"location":"development/TEST_STRATEGY_REVIEW/#2-evaluation-module-infinigramevaluationpy-93-coverage","title":"2. Evaluation Module (<code>infinigram/evaluation.py</code>) - 93% Coverage \u2705","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#test-quality-very-good","title":"Test Quality: VERY GOOD","text":"<p>What's Working Well: - End-to-end evaluation flow tested - Evaluator, BenchmarkSuite, metrics - Metrics calculations verified - Accuracy, coverage, perplexity, ranks - Test data generation tested - In-distribution and OOD creation - Model comparison framework - Multi-model, multi-dataset testing - Practical integration - RecursiveInfinigram vs vanilla Infinigram comparison</p> <p>Test Structure: <pre><code>TestEvaluator (5 tests) - Core evaluation logic\nTestBenchmarkSuite (7 tests) - Test generation and comparison\nTestSyntheticCorpus (2 tests) - Corpus generation\nTestTransformations (3 tests) - OOD transformations\nTestMetrics (2 tests) - Metric calculations\nTestPrintComparisonTable (1 test) - Output formatting\n</code></pre></p>"},{"location":"development/TEST_STRATEGY_REVIEW/#missing-coverage-14-lines-7","title":"Missing Coverage (14 lines, 7%):","text":"<p>Lines 97, 112, 131, 138-142 - Verbose progress printing: <pre><code>if verbose and i % 100 == 0:\n    print(f\"Evaluating {i}/{len(test_data)}...\")  # Line 97\n# ... more verbose prints at 112, 131, 138-142\n</code></pre> Impact: Low - These are logging statements, not critical logic Recommendation: Add one test with <code>verbose=True</code> or mark as excluded from coverage</p> <p>Lines 204-205 - Edge case in perplexity calculation: <pre><code>else:\n    perplexity = float('inf')\n    mean_probability = 0.0\n</code></pre> Impact: Medium - This handles the case where NO predictions have probability &gt; 0 Recommendation: Add test case with model that never returns predictions</p> <p>Lines 392, 399, 405-407 - Verbose comparison printing: <pre><code>if verbose:\n    print(f\"\\nEvaluating {model_name}...\")\n    # ... more verbose prints\n</code></pre> Impact: Low - Logging only Recommendation: Test with <code>verbose=True</code> or exclude</p>"},{"location":"development/TEST_STRATEGY_REVIEW/#3-recursive-module-infinigramrecursivepy-41-coverage","title":"3. Recursive Module (<code>infinigram/recursive.py</code>) - 41% Coverage \u26a0\ufe0f","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#test-quality-needs-significant-improvement","title":"Test Quality: NEEDS SIGNIFICANT IMPROVEMENT","text":"<p>What's Working Well: - Basic initialization tested - RecursiveInfinigram constructor - Cycle detection tested - Prevents infinite loops - Max depth limiting tested - Recursion bounds respected - Case normalizer tested - Simple transformer works</p> <p>Critical Gaps (159/271 lines untested):</p>"},{"location":"development/TEST_STRATEGY_REVIEW/#gap-1-synonymtransformer-core-logic-lines-70-140-146-184","title":"Gap 1: SynonymTransformer Core Logic (Lines 70-140, 146-184)","text":"<p>Untested: - <code>generate_transformations()</code> - The main transformation generation logic - Corpus inspection at match positions - Word tokenization and comparison - Synonym detection via WordNet - Transformation deduplication - Word replacement in context</p> <p>Impact: HIGH - This is core OOD handling functionality</p> <p>Current Test Limitation: <pre><code>def test_edit_distance_transformer(self):\n    transformations = transformer.generate_transformations(...)\n    # Should work without errors\n    assert isinstance(transformations, list)  # Too weak!\n</code></pre></p> <p>What's Missing: <pre><code># MISSING: Test actual transformation generation\ndef test_synonym_transformer_generates_transformations(self):\n    \"\"\"Test that synonyms are detected from corpus inspection.\"\"\"\n    corpus = b\"the feline sat on the mat\"\n    transformer = SynonymTransformer()\n\n    # Context: \"the cat sat\" (cat \u2192 feline is in corpus)\n    context = b\"the cat sat\"\n    suffix = b\"sat\"\n    positions = [find_positions_in_corpus(corpus, suffix)]\n\n    transformations = transformer.generate_transformations(\n        context=context,\n        suffix=suffix,\n        corpus=corpus,\n        match_positions=positions\n    )\n\n    # BEHAVIOR: Should generate cat\u2192feline transformation\n    assert len(transformations) &gt; 0\n    new_context, desc = transformations[0]\n    assert b\"feline\" in new_context\n    assert \"synonym\" in desc\n</code></pre></p>"},{"location":"development/TEST_STRATEGY_REVIEW/#gap-2-editdistancetransformer-lines-284-346","title":"Gap 2: EditDistanceTransformer (Lines 284-346)","text":"<p>Untested: - Typo detection and correction - Edit distance calculation - Transformation generation from corpus typos</p> <p>Impact: HIGH - Another core transformation strategy</p>"},{"location":"development/TEST_STRATEGY_REVIEW/#gap-3-prediction-combining-logic-lines-645-669","title":"Gap 3: Prediction Combining Logic (Lines 645-669)","text":"<p>Untested: - <code>_combine_predictions()</code> - Weighted combination of multiple predictions - Weight normalization - Handling empty predictions - Combining overlapping byte predictions</p> <p>Impact: HIGH - This is how recursive predictions are merged</p> <p>Missing Test: <pre><code>def test_combine_predictions_with_weights(self):\n    \"\"\"Test weighted combination of predictions.\"\"\"\n    model = RecursiveInfinigram(corpus)\n\n    # Two predictions for same byte with different weights\n    weighted_predictions = [\n        ({ord('a'): 0.8, ord('b'): 0.2}, 0.7),  # High weight\n        ({ord('a'): 0.3, ord('b'): 0.7}, 0.3),  # Low weight\n    ]\n\n    combined = model._combine_predictions(weighted_predictions)\n\n    # Should weight towards first prediction\n    assert combined[ord('a')] &gt; combined[ord('b')]\n\n    # Should normalize to sum to 1.0\n    assert abs(sum(combined.values()) - 1.0) &lt; 1e-6\n</code></pre></p>"},{"location":"development/TEST_STRATEGY_REVIEW/#gap-4-edge-cases","title":"Gap 4: Edge Cases","text":"<p>Untested scenarios: - Empty context (len=0) - No suffix matches found - All transformers return empty lists - Unicode decode errors in transformers - Very deep recursion (depth=10+) - Beam width = 1 (minimal beam) - Corpus smaller than context - Context not in corpus at all</p>"},{"location":"development/TEST_STRATEGY_REVIEW/#strategic-recommendations","title":"Strategic Recommendations","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#priority-1-critical-gaps-complete-first","title":"Priority 1: Critical Gaps (Complete First)","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#11-synonymtransformer-full-coverage","title":"1.1 SynonymTransformer Full Coverage","text":"<p>File: <code>tests/test_recursive.py</code> or create <code>tests/test_transformers.py</code></p> <pre><code>class TestSynonymTransformerBehavior:\n    \"\"\"Test SynonymTransformer contract and behavior.\"\"\"\n\n    def test_generates_transformation_from_corpus_patterns(self):\n        \"\"\"Given corpus with synonym pattern, generates transformation.\"\"\"\n        # Test BEHAVIOR: corpus inspection \u2192 transformation generation\n\n    def test_respects_word_boundaries(self):\n        \"\"\"Transformations preserve word boundaries and spacing.\"\"\"\n        # Test BEHAVIOR: whitespace handling is correct\n\n    def test_deduplicates_transformations(self):\n        \"\"\"Multiple matches don't create duplicate transformations.\"\"\"\n        # Test BEHAVIOR: deduplication works\n\n    def test_limits_transformations_per_match(self):\n        \"\"\"Only generates one transformation per match position.\"\"\"\n        # Test BEHAVIOR: prevents explosion\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#12-prediction-combining-edge-cases","title":"1.2 Prediction Combining Edge Cases","text":"<pre><code>def test_combine_predictions_empty_list(self):\n    \"\"\"Empty prediction list returns empty dict.\"\"\"\n\ndef test_combine_predictions_zero_total_weight(self):\n    \"\"\"Handles case where all weights sum to zero.\"\"\"\n\ndef test_combine_predictions_overlapping_bytes(self):\n    \"\"\"Multiple predictions for same byte are correctly weighted.\"\"\"\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#13-editdistancetransformer-coverage","title":"1.3 EditDistanceTransformer Coverage","text":"<pre><code>class TestEditDistanceTransformerBehavior:\n    def test_detects_single_char_typos(self):\n        \"\"\"Detects and corrects single-character substitutions.\"\"\"\n\n    def test_respects_max_distance(self):\n        \"\"\"Only corrects typos within max_distance.\"\"\"\n\n    def test_edit_distance_calculation_accuracy(self):\n        \"\"\"Levenshtein distance calculation is correct.\"\"\"\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#priority-2-integration-tests-add-after-p1","title":"Priority 2: Integration Tests (Add After P1)","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#21-end-to-end-transformation-flow","title":"2.1 End-to-End Transformation Flow","text":"<pre><code>def test_recursive_prediction_with_typo_corpus_mismatch(self):\n    \"\"\"\n    Given: Corpus with correct spelling\n    When: Context has typo\n    Then: RecursiveInfinigram corrects typo and makes good prediction\n    \"\"\"\n    corpus = b\"the quick brown fox jumps over the lazy dog\"\n    model = RecursiveInfinigram(corpus)\n\n    # Typo: \"quikc\" instead of \"quick\"\n    context = b\"the quikc brown\"\n    probs = model.predict(context, max_depth=2)\n\n    # Should predict ' ' (space) after \"brown\"\n    assert ord(' ') in probs\n    assert probs[ord(' ')] &gt; 0.5\n\ndef test_recursive_prediction_with_synonym_corpus_mismatch(self):\n    \"\"\"Tests synonym transformation enables prediction.\"\"\"\n    # Similar end-to-end test with synonyms\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#22-scorer-integration","title":"2.2 Scorer Integration","text":"<pre><code>def test_scorer_weights_affect_prediction_ranking(self):\n    \"\"\"Conservative vs aggressive scorer changes prediction distribution.\"\"\"\n    corpus = b\"test corpus\"\n\n    conservative = RecursiveInfinigram(corpus, scorer=create_conservative_scorer())\n    aggressive = RecursiveInfinigram(corpus, scorer=create_aggressive_scorer())\n\n    context = b\"transformed context\"\n\n    probs_conservative = conservative.predict(context)\n    probs_aggressive = aggressive.predict(context)\n\n    # Distributions should differ based on scorer\n    assert probs_conservative != probs_aggressive\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#priority-3-robustness-tests-add-after-p1-p2","title":"Priority 3: Robustness Tests (Add After P1 &amp; P2)","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#31-error-handling","title":"3.1 Error Handling","text":"<pre><code>def test_unicode_decode_error_in_synonym_detection(self):\n    \"\"\"Invalid UTF-8 bytes don't crash synonym detection.\"\"\"\n\ndef test_empty_corpus_handling(self):\n    \"\"\"Empty corpus doesn't crash initialization.\"\"\"\n\ndef test_context_longer_than_corpus(self):\n    \"\"\"Context longer than corpus handled gracefully.\"\"\"\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#32-performance-edge-cases","title":"3.2 Performance Edge Cases","text":"<pre><code>def test_deep_recursion_performance(self):\n    \"\"\"Very deep recursion doesn't cause stack overflow.\"\"\"\n\ndef test_large_beam_width_manageable(self):\n    \"\"\"Large beam widths don't cause memory explosion.\"\"\"\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#test-organization-assessment","title":"Test Organization Assessment","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#current-structure-good","title":"Current Structure: GOOD","text":"<pre><code>tests/\n\u251c\u2500\u2500 test_recursive.py          # 10 tests - Basic structure only\n\u251c\u2500\u2500 test_scoring.py            # 33 tests - EXCELLENT\n\u251c\u2500\u2500 test_evaluation.py         # 20 tests - VERY GOOD\n\u251c\u2500\u2500 test_wordnet_integration.py    # 14 tests - Failing (numpy issue)\n\u2514\u2500\u2500 test_corpus_guided_transformations.py  # 11 tests - Failing\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#recommended-structure","title":"Recommended Structure:","text":"<pre><code>tests/\n\u251c\u2500\u2500 test_recursive.py          # Keep integration tests here\n\u251c\u2500\u2500 test_transformers.py       # NEW: Dedicated transformer tests\n\u2502   \u251c\u2500\u2500 TestSynonymTransformerBehavior\n\u2502   \u251c\u2500\u2500 TestEditDistanceTransformerBehavior\n\u2502   \u2514\u2500\u2500 TestCaseNormalizerBehavior\n\u251c\u2500\u2500 test_scoring.py            # Keep as-is (100% coverage)\n\u251c\u2500\u2500 test_evaluation.py         # Keep as-is (93% coverage)\n\u251c\u2500\u2500 test_recursive_integration.py  # NEW: End-to-end workflows\n\u2502   \u251c\u2500\u2500 TestTypoCorrectionFlow\n\u2502   \u251c\u2500\u2500 TestSynonymHandlingFlow\n\u2502   \u2514\u2500\u2500 TestScorerIntegration\n\u2514\u2500\u2500 test_edge_cases.py         # NEW: Robustness and error handling\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#test-quality-anti-patterns-found","title":"Test Quality Anti-Patterns Found","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#anti-pattern-1-too-weak-assertions-test_recursivepy","title":"\u274c Anti-Pattern 1: Too-Weak Assertions (test_recursive.py)","text":"<pre><code># BAD: Only checks type, not behavior\nassert isinstance(transformations, list)\n\n# GOOD: Checks behavior\nassert len(transformations) &gt; 0\nassert any(\"synonym\" in desc for _, desc in transformations)\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#anti-pattern-2-no-assertions-on-core-logic","title":"\u274c Anti-Pattern 2: No Assertions on Core Logic","text":"<pre><code>def test_basic_prediction(self, simple_corpus):\n    probs = model.predict(context, max_depth=1)\n    assert isinstance(probs, dict)\n    # May be empty if no matches, that's ok for now  # \u2190 This is a gap!\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#anti-pattern-fixed-excellent-behavioral-tests-test_scoringpy","title":"\u2705 Anti-Pattern Fixed: Excellent Behavioral Tests (test_scoring.py)","text":"<pre><code># EXCELLENT: Tests observable property\ndef test_longer_match_higher_score(self):\n    score_long = scorer.score(..., match_length=15, ...)\n    score_short = scorer.score(..., match_length=5, ...)\n    assert score_long &gt; score_short\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#specific-test-recommendations","title":"Specific Test Recommendations","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#new-tests-to-add-to-test_recursivepy","title":"New Tests to Add to <code>test_recursive.py</code>","text":"<pre><code>class TestRecursiveInfinigramPredictionCombining:\n    \"\"\"Test prediction combining logic.\"\"\"\n\n    def test_combine_empty_predictions_returns_empty(self):\n        \"\"\"Empty prediction list returns empty dict.\"\"\"\n        model = RecursiveInfinigram(b\"test corpus\")\n        result = model._combine_predictions([])\n        assert result == {}\n\n    def test_combine_single_prediction_normalizes(self):\n        \"\"\"Single prediction is normalized to sum to 1.0.\"\"\"\n        model = RecursiveInfinigram(b\"test corpus\")\n        weighted_preds = [({65: 0.3, 66: 0.7}, 1.0)]\n        result = model._combine_predictions(weighted_preds)\n        assert abs(sum(result.values()) - 1.0) &lt; 1e-9\n\n    def test_combine_respects_weights(self):\n        \"\"\"Higher weight predictions contribute more.\"\"\"\n        model = RecursiveInfinigram(b\"test corpus\")\n        weighted_preds = [\n            ({65: 1.0}, 0.9),  # High weight for 'A'\n            ({66: 1.0}, 0.1),  # Low weight for 'B'\n        ]\n        result = model._combine_predictions(weighted_preds)\n        assert result[65] &gt; result[66]\n\n    def test_combine_overlapping_predictions_sum(self):\n        \"\"\"Overlapping byte predictions are summed.\"\"\"\n        model = RecursiveInfinigram(b\"test corpus\")\n        weighted_preds = [\n            ({65: 0.5}, 0.5),\n            ({65: 0.8}, 0.5),\n        ]\n        result = model._combine_predictions(weighted_preds)\n        # (0.5*0.5 + 0.8*0.5) / (0.5*0.5 + 0.8*0.5) = 1.0\n        assert abs(result[65] - 1.0) &lt; 1e-9\n\n\nclass TestSynonymTransformerCorpusInspection:\n    \"\"\"Test corpus inspection and transformation generation.\"\"\"\n\n    def test_inspects_corpus_at_match_positions(self):\n        \"\"\"Transformer looks at corpus before match positions.\"\"\"\n        corpus = b\"the big cat sat. the large cat stood.\"\n        transformer = SynonymTransformer(use_wordnet=False)  # Avoid nltk\n\n        context = b\"the small cat sat\"\n        suffix = b\"sat\"\n\n        # Find where \"sat\" appears in corpus\n        positions = [i for i in range(len(corpus)) if corpus[i:i+3] == suffix]\n\n        transformations = transformer.generate_transformations(\n            context=context,\n            suffix=suffix,\n            corpus=corpus,\n            match_positions=positions\n        )\n\n        # Should inspect corpus and see words differ\n        # (Actual synonym detection depends on WordNet)\n        assert isinstance(transformations, list)\n\n    def test_preserves_suffix_in_transformation(self):\n        \"\"\"Generated transformation preserves the matched suffix.\"\"\"\n        corpus = b\"test suffix match\"\n        transformer = SynonymTransformer(use_wordnet=False)\n\n        context = b\"other suffix\"\n        suffix = b\"suffix\"\n        positions = [5]  # \"suffix\" at position 5 in corpus\n\n        transformations = transformer.generate_transformations(\n            context=context,\n            suffix=suffix,\n            corpus=corpus,\n            match_positions=positions\n        )\n\n        # All transformations should preserve suffix\n        for new_context, desc in transformations:\n            assert new_context.endswith(suffix)\n\n\nclass TestEditDistanceTransformerCorrectness:\n    \"\"\"Test edit distance transformer produces correct transformations.\"\"\"\n\n    def test_edit_distance_calculation_is_accurate(self):\n        \"\"\"Levenshtein distance calculation matches expected values.\"\"\"\n        transformer = EditDistanceTransformer()\n\n        # Known edit distances\n        assert transformer._edit_distance(b\"cat\", b\"cat\") == 0\n        assert transformer._edit_distance(b\"cat\", b\"bat\") == 1\n        assert transformer._edit_distance(b\"cat\", b\"dog\") == 3\n        assert transformer._edit_distance(b\"sitting\", b\"kitten\") == 3\n\n    def test_only_corrects_within_max_distance(self):\n        \"\"\"Respects max_distance parameter.\"\"\"\n        transformer = EditDistanceTransformer(max_distance=1)\n\n        corpus = b\"the cat sat on the mat\"\n        context = b\"the dog sat\"  # \"dog\" vs \"cat\" = distance 3\n        suffix = b\"sat\"\n        positions = [8]\n\n        transformations = transformer.generate_transformations(\n            context=context,\n            suffix=suffix,\n            corpus=corpus,\n            match_positions=positions\n        )\n\n        # Should NOT generate transformation (distance too large)\n        # (This depends on the words lining up correctly)\n        assert isinstance(transformations, list)\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#new-tests-to-add-to-test_evaluationpy","title":"New Tests to Add to <code>test_evaluation.py</code>","text":"<pre><code>class TestEvaluatorEdgeCases:\n    \"\"\"Test evaluator edge cases.\"\"\"\n\n    def test_evaluate_with_no_predictions(self):\n        \"\"\"Handles model that never returns predictions.\"\"\"\n        # Create a model that always returns empty dict\n        class NoOpModel:\n            def predict(self, context, top_k=10):\n                return {}\n\n        model = NoOpModel()\n        evaluator = Evaluator(model, \"NoOp\")\n\n        test_data = [(b\"test\", b\"x\")]\n        metrics, results = evaluator.evaluate(test_data)\n\n        # Coverage should be 0%\n        assert metrics.coverage == 0.0\n        # Perplexity should be infinity\n        assert metrics.perplexity == float('inf')\n        # Mean probability should be 0\n        assert metrics.mean_probability == 0.0\n\n    def test_evaluate_with_verbose_output(self):\n        \"\"\"Verbose mode prints progress (coverage for logging).\"\"\"\n        corpus = b\"test corpus\"\n        model = Infinigram(corpus)\n        evaluator = Evaluator(model, \"Test\")\n\n        test_data = [(b\"te\", b\"s\")] * 100  # 100 samples\n\n        # This should print progress at multiples of 100\n        metrics, results = evaluator.evaluate(test_data, verbose=True)\n\n        assert len(results) == 100\n</code></pre>"},{"location":"development/TEST_STRATEGY_REVIEW/#missing-test-scenarios-by-feature","title":"Missing Test Scenarios by Feature","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#recursiveinfinigram-core-functionality","title":"RecursiveInfinigram Core Functionality","text":"Feature Current Coverage Missing Tests Transformation generation 20% Corpus inspection logic, word comparison Synonym detection 0% WordNet integration, similarity thresholds Typo correction 10% Edit distance, max_distance enforcement Prediction combining 0% Weight normalization, empty predictions Beam search 40% Beam width limiting, scoring cutoff Cycle detection 100% \u2705 None Max depth 100% \u2705 None"},{"location":"development/TEST_STRATEGY_REVIEW/#edge-cases-and-error-handling","title":"Edge Cases and Error Handling","text":"Scenario Tested? Priority Empty corpus \u274c High Empty context \u274c High No suffix matches \u274c High Unicode decode errors \u274c Medium Context longer than corpus \u274c Medium Very deep recursion (10+) \u274c Low Large beam width (100+) \u274c Low Zero probability predictions \u274c Medium"},{"location":"development/TEST_STRATEGY_REVIEW/#integration-scenarios","title":"Integration Scenarios","text":"Integration Path Tested? Priority Transformer \u2192 Scorer \u2192 Predictor \u274c High Conservative vs Aggressive scorer impact \u274c High Multiple transformations in sequence \u274c Medium Transformation + prediction explanation Partial Medium Benchmark suite with real OOD data Partial Low"},{"location":"development/TEST_STRATEGY_REVIEW/#recommendations-summary","title":"Recommendations Summary","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#immediate-actions-complete-in-1-2-days","title":"Immediate Actions (Complete in 1-2 days)","text":"<ol> <li>Add transformation generation tests (Priority 1.1)</li> <li>Test <code>SynonymTransformer.generate_transformations()</code> with real examples</li> <li>Test <code>EditDistanceTransformer.generate_transformations()</code> with typos</li> <li> <p>Verify corpus inspection logic works correctly</p> </li> <li> <p>Add prediction combining tests (Priority 1.2)</p> </li> <li>Test empty predictions, zero weights, normalization</li> <li>Test overlapping byte predictions are summed correctly</li> <li> <p>Test weight distribution affects final predictions</p> </li> <li> <p>Add EditDistanceTransformer unit tests (Priority 1.3)</p> </li> <li>Test edit distance calculation accuracy</li> <li>Test max_distance parameter enforcement</li> <li>Test typo detection and correction logic</li> </ol>"},{"location":"development/TEST_STRATEGY_REVIEW/#short-term-improvements-complete-in-1-week","title":"Short-term Improvements (Complete in 1 week)","text":"<ol> <li>Add end-to-end integration tests (Priority 2.1)</li> <li>Test full typo correction \u2192 prediction flow</li> <li>Test full synonym handling \u2192 prediction flow</li> <li> <p>Verify explanations are generated correctly</p> </li> <li> <p>Add scorer integration tests (Priority 2.2)</p> </li> <li>Test conservative vs aggressive scorer impact on predictions</li> <li> <p>Verify scorer weights affect transformation selection</p> </li> <li> <p>Fix evaluation.py coverage gaps (Small task)</p> </li> <li>Add test with <code>verbose=True</code> to cover logging</li> <li>Add test for \"no predictions\" edge case (lines 204-205)</li> </ol>"},{"location":"development/TEST_STRATEGY_REVIEW/#long-term-quality-improvements-complete-in-2-3-weeks","title":"Long-term Quality Improvements (Complete in 2-3 weeks)","text":"<ol> <li>Add robustness tests (Priority 3)</li> <li>Test error handling (Unicode, empty inputs)</li> <li>Test performance edge cases (deep recursion, large beam)</li> <li> <p>Add property-based tests with Hypothesis</p> </li> <li> <p>Refactor test organization</p> </li> <li>Create <code>test_transformers.py</code> for dedicated transformer tests</li> <li>Create <code>test_recursive_integration.py</code> for end-to-end tests</li> <li>Create <code>test_edge_cases.py</code> for robustness tests</li> </ol>"},{"location":"development/TEST_STRATEGY_REVIEW/#coverage-goals","title":"Coverage Goals","text":""},{"location":"development/TEST_STRATEGY_REVIEW/#target-coverage-by-module-3-month-timeline","title":"Target Coverage by Module (3-month timeline)","text":"Module Current Target Priority scoring.py 100% \u2705 100% Maintain evaluation.py 93% 98% Low (close logging gaps) recursive.py 41% \u26a0\ufe0f 85% HIGH"},{"location":"development/TEST_STRATEGY_REVIEW/#lines-to-focus-on-recursivepy","title":"Lines to Focus On (recursive.py)","text":"<p>High Value (Core Logic): - Lines 70-140: SynonymTransformer.generate_transformations() - Lines 284-346: EditDistanceTransformer.generate_transformations() - Lines 645-669: _combine_predictions() - Lines 536-607: _recursive_transform()</p> <p>Medium Value (Supporting Logic): - Lines 146-184: _are_synonyms() and WordNet integration - Lines 233-266: _replace_word_in_context() - Lines 352-372: _edit_distance()</p> <p>Lower Value (Helper Methods): - Lines 609-643: _find_best_suffix_match(), _find_all_suffix_matches() - Lines 671-731: predict_with_explanation()</p>"},{"location":"development/TEST_STRATEGY_REVIEW/#conclusion","title":"Conclusion","text":"<p>The Infinigram test suite demonstrates strong test engineering practices in the scoring and evaluation modules, with behavioral tests that would remain valid even after significant refactoring. The scoring module in particular is an excellent example of TDD done right.</p> <p>However, the recursive transformation system needs significant test attention. The 41% coverage represents untested core logic that handles OOD generalization - arguably the most important innovation in the system.</p> <p>Key Action Items: 1. Add 15-20 focused tests for transformer generation logic (P1) 2. Add 5-10 tests for prediction combining (P1) 3. Add 10-15 integration tests for end-to-end flows (P2) 4. Reach 85% coverage on recursive.py within 3 months</p> <p>The existing test structure is sound and can accommodate these additions with minimal refactoring. The scoring tests provide an excellent template for how to write resilient, behavioral tests.</p>"},{"location":"features/SCORING_AND_EVALUATION/","title":"Transformation Scoring and Evaluation Framework","text":""},{"location":"features/SCORING_AND_EVALUATION/#overview","title":"Overview","text":"<p>This document describes the transformation scoring system and evaluation framework for Infinigram's OOD generalization features.</p>"},{"location":"features/SCORING_AND_EVALUATION/#transformation-scoring-system","title":"Transformation Scoring System","text":""},{"location":"features/SCORING_AND_EVALUATION/#motivation","title":"Motivation","text":"<p>When using <code>predict_search()</code> to beam search over multiple transform combinations, each transformed context may produce different predictions. We need to weight these predictions based on:</p> <ol> <li>How good the suffix match is</li> <li>How frequently the pattern appears in the corpus</li> <li>How reliable the transformations are</li> <li>How many transformations were applied</li> </ol>"},{"location":"features/SCORING_AND_EVALUATION/#architecture","title":"Architecture","text":""},{"location":"features/SCORING_AND_EVALUATION/#transformationscorer-class","title":"TransformationScorer Class","text":"<p>Location: <code>infinigram/scoring.py</code></p> <pre><code>class TransformationScorer:\n    \"\"\"\n    Scores transformed contexts for weighted prediction combining.\n\n    Considers multiple factors:\n    - Match length (longer = better)\n    - Match frequency (more occurrences = more confident)\n    - Transformation depth (fewer transformations = better)\n    - Transformation type (some transformers more reliable)\n    \"\"\"\n</code></pre>"},{"location":"features/SCORING_AND_EVALUATION/#scoring-components","title":"Scoring Components","text":"<p>The scorer computes a final score in [0, 1] as a weighted combination of four components:</p> <p>1. Match Length Score (default weight: 0.4) - Longer matches = more confident predictions - Uses sqrt for diminishing returns</p> <p>2. Match Frequency Score (default weight: 0.2) - More occurrences = more confident - Uses logarithmic scaling</p> <p>3. Transformation Quality Score (default weight: 0.3) - Different transformers have different reliability - Current transform reliability weights:   - <code>case</code>: 0.99 (case normalization is very safe)   - <code>lowercase</code>/<code>uppercase</code>/<code>casefold</code>: 0.99   - <code>strip</code>/<code>normalize_whitespace</code>: 0.99</p> <p>4. Depth Penalty Score (default weight: 0.1) - Fewer transformations = better (closer to original) - Uses exponential decay</p>"},{"location":"features/SCORING_AND_EVALUATION/#scorer-presets","title":"Scorer Presets","text":"<p>Three preset configurations are provided:</p> <p>1. Default Scorer <pre><code>create_default_scorer()\n# Balanced: (0.4, 0.2, 0.3, 0.1)\n</code></pre></p> <p>2. Conservative Scorer <pre><code>create_conservative_scorer()\n# Match-focused: (0.5, 0.2, 0.1, 0.2)\n</code></pre> Use when corpus coverage is high.</p> <p>3. Aggressive Scorer <pre><code>create_aggressive_scorer()\n# Transformation-friendly: (0.3, 0.3, 0.3, 0.1)\n</code></pre> Use for OOD scenarios where corpus coverage is low.</p>"},{"location":"features/SCORING_AND_EVALUATION/#evaluation-framework","title":"Evaluation Framework","text":""},{"location":"features/SCORING_AND_EVALUATION/#architecture_1","title":"Architecture","text":"<p>Location: <code>infinigram/evaluation.py</code></p> <p>The evaluation framework provides tools to: 1. Evaluate models on test data 2. Create in-distribution and OOD test sets 3. Compare multiple models 4. Generate comprehensive metrics</p>"},{"location":"features/SCORING_AND_EVALUATION/#components","title":"Components","text":""},{"location":"features/SCORING_AND_EVALUATION/#1-evaluator","title":"1. Evaluator","text":"<p>Evaluates a single model on test data.</p> <pre><code>evaluator = Evaluator(model, model_name=\"My Model\")\nmetrics, results = evaluator.evaluate(test_data, top_k=10)\n</code></pre>"},{"location":"features/SCORING_AND_EVALUATION/#2-benchmarksuite","title":"2. BenchmarkSuite","text":"<p>Creates test datasets and compares models.</p> <pre><code>suite = BenchmarkSuite(corpus)\n\n# Create test sets\nin_dist = suite.create_in_distribution_test(num_samples=200)\nood_case = suite.create_ood_test(['case'], num_samples=200)\n\n# Compare models\nvanilla = Infinigram(corpus)\nwith_transforms = Infinigram(corpus, default_transforms=['lowercase'])\n\nresults = suite.compare_models(\n    models={\"Vanilla\": vanilla, \"WithTransforms\": with_transforms},\n    test_datasets={\"In-Dist\": in_dist, \"OOD-Case\": ood_case}\n)\n</code></pre>"},{"location":"features/SCORING_AND_EVALUATION/#3-metrics","title":"3. Metrics","text":"<pre><code>@dataclass\nclass EvaluationMetrics:\n    # Accuracy metrics\n    accuracy: float  # % of correct predictions\n    top_k_accuracy: Dict[int, float]  # Top-k accuracy\n    mean_rank: float  # Average rank of correct token\n\n    # Coverage metrics\n    coverage: float  # % with predictions\n    no_match_rate: float  # % with no match\n\n    # Quality metrics\n    perplexity: float  # Lower = better\n    mean_probability: float  # Avg prob of correct token\n\n    # Performance metrics\n    mean_time_ms: float  # Avg prediction time\n    total_time_s: float  # Total evaluation time\n</code></pre>"},{"location":"features/SCORING_AND_EVALUATION/#ood-test-generation","title":"OOD Test Generation","text":"<p>The framework can automatically create OOD test data:</p> <p>1. Case Variations <pre><code>ood_case = suite.create_ood_test(['case'], num_samples=100)\n# \"the quick brown\" -&gt; \"ThE QuIcK BroWN\"\n</code></pre></p> <p>2. Typos (for testing purposes) <pre><code>ood_typo = suite.create_ood_test(['typo'], num_samples=100)\n# \"the quick brown\" -&gt; \"teh qwick brown\"\n</code></pre></p> <p>3. Combined <pre><code>ood_multi = suite.create_ood_test(['case', 'typo'], num_samples=100)\n</code></pre></p>"},{"location":"features/SCORING_AND_EVALUATION/#running-benchmarks","title":"Running Benchmarks","text":"<pre><code>from infinigram.infinigram import Infinigram\nfrom infinigram.evaluation import BenchmarkSuite, print_comparison_table\n\n# Create models with different configurations\ncorpus = b\"your training data\"\nvanilla = Infinigram(corpus)\nwith_transforms = Infinigram(corpus, default_transforms=['lowercase'])\n\n# Create benchmark suite\nsuite = BenchmarkSuite(corpus)\n\n# Create test datasets\ntest_datasets = {\n    \"In-Dist\": suite.create_in_distribution_test(100),\n    \"OOD-Case\": suite.create_ood_test(['case'], 100),\n}\n\n# Compare\nresults = suite.compare_models(\n    models={\"Vanilla\": vanilla, \"WithTransforms\": with_transforms},\n    test_datasets=test_datasets\n)\n\n# Print results\nprint_comparison_table(results)\n</code></pre>"},{"location":"features/SCORING_AND_EVALUATION/#test-coverage","title":"Test Coverage","text":""},{"location":"features/SCORING_AND_EVALUATION/#scoring-tests","title":"Scoring Tests","text":"<p>Location: <code>tests/test_scoring.py</code></p> <ul> <li>Score ranges [0, 1]</li> <li>Longer matches score higher</li> <li>More frequent patterns score higher</li> <li>Fewer transformations score higher</li> <li>Factory functions (default, conservative, aggressive)</li> </ul>"},{"location":"features/SCORING_AND_EVALUATION/#evaluation-tests","title":"Evaluation Tests","text":"<p>Location: <code>tests/test_evaluation.py</code></p> <ul> <li>Evaluator initialization and basic evaluation</li> <li>Accuracy and coverage calculation</li> <li>Top-k accuracy and perplexity calculation</li> <li>In-distribution and OOD test creation</li> <li>Model comparison</li> </ul>"},{"location":"features/SCORING_AND_EVALUATION/#future-enhancements","title":"Future Enhancements","text":""},{"location":"features/SCORING_AND_EVALUATION/#planned-ood-features-deferred","title":"Planned OOD Features (Deferred)","text":"<p>The following features are planned but deferred due to runtime performance concerns:</p> <ol> <li>Synonym transforms: Corpus-guided word replacement</li> <li>Would require WordNet integration or embedding similarity</li> <li> <p>Runtime cost could be significant</p> </li> <li> <p>Typo correction: Edit-distance based transforms</p> </li> <li>Would need fuzzy suffix arrays or BK-trees for efficiency</li> <li>Current implementation only for test data generation</li> </ol>"},{"location":"features/SCORING_AND_EVALUATION/#scoring-system-improvements","title":"Scoring System Improvements","text":"<ol> <li>Adaptive Weights: Learn optimal weights from validation data</li> <li>Context-Aware Scoring: Use context length and complexity</li> <li>Confidence Intervals: Provide uncertainty estimates</li> </ol>"},{"location":"features/SCORING_AND_EVALUATION/#evaluation-framework-improvements","title":"Evaluation Framework Improvements","text":"<ol> <li>Cross-Validation: k-fold evaluation</li> <li>Statistical Significance: Hypothesis testing</li> <li>Error Analysis: Categorize and analyze errors</li> <li>Visualization: Plot ROC curves, confusion matrices</li> </ol>"},{"location":"features/SCORING_AND_EVALUATION/#references","title":"References","text":"<ul> <li>Source code: <code>infinigram/scoring.py</code>, <code>infinigram/evaluation.py</code></li> <li>Tests: <code>tests/test_scoring.py</code>, <code>tests/test_evaluation.py</code></li> </ul>"},{"location":"guides/BENCHMARKS/","title":"Infinigram Benchmarks and Evaluation","text":""},{"location":"guides/BENCHMARKS/#overview","title":"Overview","text":"<p>This document presents benchmark results comparing vanilla Infinigram with RecursiveInfinigram on both in-distribution and out-of-distribution (OOD) test scenarios.</p>"},{"location":"guides/BENCHMARKS/#methodology","title":"Methodology","text":""},{"location":"guides/BENCHMARKS/#corpus","title":"Corpus","text":"<ul> <li>Size: 50,021 bytes</li> <li>Type: Synthetic English text</li> <li>Content: Common English words in random sentences</li> </ul>"},{"location":"guides/BENCHMARKS/#models-compared","title":"Models Compared","text":"<ol> <li>Vanilla Infinigram: Standard n-gram language model with suffix array</li> <li>RecursiveInfinigram: Enhanced model with transformation-based OOD handling</li> <li>CaseNormalizer</li> <li>EditDistanceTransformer (max_distance=1)</li> <li>SynonymTransformer (WordNet-based)</li> <li>TransformationScorer (multi-factor weighting)</li> </ol>"},{"location":"guides/BENCHMARKS/#test-datasets","title":"Test Datasets","text":"<ol> <li>In-Distribution (200 samples): Random excerpts from training corpus</li> <li>OOD: Case Changes (200 samples): Random case flips (30% of letters)</li> <li>OOD: Typos (200 samples): 1-2 character substitutions</li> <li>OOD: Case + Typos (200 samples): Combined transformations</li> </ol>"},{"location":"guides/BENCHMARKS/#metrics","title":"Metrics","text":"<ul> <li>Accuracy: % of correct top-1 predictions</li> <li>Top-k Accuracy: % where correct prediction is in top-k</li> <li>Coverage: % of contexts that have predictions</li> <li>Perplexity: Language model quality metric (lower = better)</li> <li>Mean Probability: Average probability assigned to correct token</li> <li>Mean Rank: Average rank of correct prediction</li> <li>Time: Average prediction time in milliseconds</li> </ul>"},{"location":"guides/BENCHMARKS/#results-summary","title":"Results Summary","text":""},{"location":"guides/BENCHMARKS/#comparison-table","title":"Comparison Table","text":"Dataset Model Accuracy Top-3 Acc Perplexity Time (ms) In-Distribution Vanilla 100.0% 100.0% 1.00 1.46 Recursive 100.0% 100.0% 1.00 3.92 OOD: Case Changes Vanilla 52.5% 67.0% 3.05 1.23 Recursive 74.5% 81.5% 1.95 96.12 OOD: Typos Vanilla 76.5% 86.0% 1.59 0.99 Recursive 82.5% 88.5% 1.43 20.44 OOD: Case + Typos Vanilla 40.5% 63.0% 3.85 1.17 Recursive 61.0% 73.0% 2.31 71.33"},{"location":"guides/BENCHMARKS/#improvement-over-vanilla","title":"Improvement Over Vanilla","text":"Dataset Accuracy \u0394 Perplexity \u0394 In-Distribution +0.0% +0.0% OOD: Case Changes +22.0% +36.2% OOD: Typos +6.0% +10.2% OOD: Case + Typos +20.5% +40.0%"},{"location":"guides/BENCHMARKS/#detailed-analysis","title":"Detailed Analysis","text":""},{"location":"guides/BENCHMARKS/#in-distribution-performance","title":"In-Distribution Performance","text":"<p>Both models achieve perfect performance (100% accuracy, perplexity 1.00) on in-distribution data, as expected. RecursiveInfinigram is slightly slower (3.92ms vs 1.46ms) due to transformation overhead, but this is negligible in practice.</p>"},{"location":"guides/BENCHMARKS/#ood-case-changes","title":"OOD: Case Changes","text":"<p>Scenario: Input has random case changes (e.g., \"ThE QuIcK BroWN\")</p> <p>Results: - Vanilla struggles with case variations (52.5% accuracy) - RecursiveInfinigram handles them well via CaseNormalizer (74.5% accuracy) - 22 percentage point improvement in accuracy - 36% reduction in perplexity</p> <p>Why it works: CaseNormalizer transforms \"ThE QuIcK\" \u2192 \"the quick\" before querying, finding matches in the original corpus.</p>"},{"location":"guides/BENCHMARKS/#ood-typos","title":"OOD: Typos","text":"<p>Scenario: Input has 1-2 character typos (e.g., \"the qwick brown\")</p> <p>Results: - Vanilla has some resilience due to partial matches (76.5% accuracy) - RecursiveInfinigram improves via EditDistanceTransformer (82.5% accuracy) - 6 percentage point improvement in accuracy - 10% reduction in perplexity</p> <p>Why it works: EditDistanceTransformer detects corpus words within edit distance 1, suggesting \"qwick\" \u2192 \"quick\" correction.</p>"},{"location":"guides/BENCHMARKS/#ood-case-typos-hardest","title":"OOD: Case + Typos (Hardest)","text":"<p>Scenario: Combined case changes and typos (e.g., \"ThE qwIcK BroWN\")</p> <p>Results: - Vanilla struggles significantly (40.5% accuracy) - RecursiveInfinigram shows strong robustness (61.0% accuracy) - 20.5 percentage point improvement in accuracy - 40% reduction in perplexity</p> <p>Why it works: Multiple transformers can chain together: 1. CaseNormalizer: \"ThE qwIcK\" \u2192 \"the qwick\" 2. EditDistanceTransformer: \"the qwick\" \u2192 \"the quick\" 3. Result: Successfully recovers original context</p>"},{"location":"guides/BENCHMARKS/#performance-trade-offs","title":"Performance Trade-offs","text":""},{"location":"guides/BENCHMARKS/#speed","title":"Speed","text":"<p>RecursiveInfinigram is slower than vanilla due to transformation overhead:</p> <ul> <li>In-Distribution: 2.7x slower (3.92ms vs 1.46ms)</li> <li>OOD: Case Changes: 78x slower (96.12ms vs 1.23ms)</li> <li>OOD: Typos: 21x slower (20.44ms vs 0.99ms)</li> <li>OOD: Case + Typos: 61x slower (71.33ms vs 1.17ms)</li> </ul> <p>Why: RecursiveInfinigram tries multiple transformations, each requiring: - Transformation generation (corpus inspection) - New suffix array queries - Scoring and ranking</p> <p>Mitigation strategies: - Cache transformation results - Limit transformation depth - Use conservative scorer when corpus coverage is high - Prune low-scoring transformations early</p>"},{"location":"guides/BENCHMARKS/#memory","title":"Memory","text":"<p>RecursiveInfinigram has similar memory footprint to vanilla: - Same suffix array - Additional: transformation cache (~KB) - Additional: scorer state (~bytes)</p>"},{"location":"guides/BENCHMARKS/#when-to-use-each-model","title":"When to Use Each Model","text":""},{"location":"guides/BENCHMARKS/#use-vanilla-infinigram-when","title":"Use Vanilla Infinigram When:","text":"<ul> <li>Input is in-distribution (matches training corpus well)</li> <li>Speed is critical</li> <li>Corpus coverage is very high</li> <li>You don't expect typos, case variations, or paraphrasing</li> </ul>"},{"location":"guides/BENCHMARKS/#use-recursiveinfinigram-when","title":"Use RecursiveInfinigram When:","text":"<ul> <li>Input may have typos or spelling errors</li> <li>Input may have case variations</li> <li>Input may use synonyms not in corpus</li> <li>Robustness is more important than speed</li> <li>Working with OOD data (new domains, user-generated content)</li> </ul>"},{"location":"guides/BENCHMARKS/#scoring-system-impact","title":"Scoring System Impact","text":"<p>The TransformationScorer uses multi-factor weighting:</p> <ol> <li>Match Length (40%): Longer suffix matches are better</li> <li>Match Frequency (20%): More common patterns are more confident</li> <li>Transformation Quality (30%): Different transformers have different reliability</li> <li>Depth Penalty (10%): Fewer transformations are better</li> </ol>"},{"location":"guides/BENCHMARKS/#transformer-reliability-weights","title":"Transformer Reliability Weights","text":"<ul> <li>Case normalization: 0.99 (very reliable)</li> <li>Typo correction: 0.95 (reliable)</li> <li>Synonym replacement: 0.85 (less reliable, meaning can shift)</li> </ul> <p>This weighting ensures that: - Original context (no transformations) scores highest when it has good matches - Case-normalized contexts score almost as high as originals - Synonym-based transformations are used cautiously</p>"},{"location":"guides/BENCHMARKS/#conclusion","title":"Conclusion","text":"<p>RecursiveInfinigram demonstrates significant improvements on out-of-distribution data:</p> <ul> <li>+22% accuracy on case variations</li> <li>+6% accuracy on typos</li> <li>+20.5% accuracy on combined challenges</li> <li>Up to 40% perplexity reduction on hard OOD scenarios</li> </ul> <p>The trade-off is higher latency (2-78x slower), but this is acceptable for many applications where robustness is critical.</p> <p>The transformation-based approach successfully handles: - \u2705 Case variations - \u2705 Typos and spelling errors - \u2705 Synonyms (via WordNet) - \u2705 Multiple simultaneous transformations</p>"},{"location":"guides/BENCHMARKS/#running-benchmarks","title":"Running Benchmarks","text":"<p>To reproduce these results:</p> <pre><code>python3 examples/run_benchmark.py\n</code></pre> <p>To run on your own corpus:</p> <pre><code>from infinigram.evaluation import BenchmarkSuite\nfrom infinigram.infinigram import Infinigram\nfrom infinigram.recursive import RecursiveInfinigram, CaseNormalizer\n\n# Your corpus\ncorpus = b\"your training data here\"\n\n# Create models\nvanilla = Infinigram(corpus)\nrecursive = RecursiveInfinigram(corpus, transformers=[CaseNormalizer()])\n\n# Create benchmark suite\nsuite = BenchmarkSuite(corpus)\n\n# Create test datasets\nin_dist = suite.create_in_distribution_test(num_samples=100)\nood_case = suite.create_ood_test(['case'], num_samples=100)\n\n# Compare\nresults = suite.compare_models(\n    models={\"Vanilla\": vanilla, \"Recursive\": recursive},\n    test_datasets={\"In-Dist\": in_dist, \"OOD\": ood_case}\n)\n\n# Print results\nfrom infinigram.evaluation import print_comparison_table\nprint_comparison_table(results)\n</code></pre>"},{"location":"guides/BENCHMARKS/#test-coverage","title":"Test Coverage","text":"<p>The evaluation framework has comprehensive test coverage:</p> <ul> <li>20 evaluation tests (test_evaluation.py)</li> <li>33 scoring tests (test_scoring.py)</li> <li>43 recursive tests (test_recursive.py + others)</li> <li>Total: 96 tests passing</li> </ul>"},{"location":"guides/BENCHMARKS/#future-work","title":"Future Work","text":"<p>Potential improvements:</p> <ol> <li>Faster transformations: Cache corpus-guided transformations</li> <li>Better scoring: Learn weights from validation data</li> <li>More transformers: Stemming, lemmatization, abbreviations</li> <li>Beam pruning: Prune low-scoring transformations early</li> <li>Parallel transformations: Try transformations in parallel</li> <li>Context-aware synonyms: Use context to disambiguate word senses</li> </ol>"},{"location":"guides/LOADING_DATASETS/","title":"Loading Datasets in Infinigram","text":""},{"location":"guides/LOADING_DATASETS/#quick-answer","title":"Quick Answer","text":"<p>No, you don't need an absolute path! You can use either: 1. Relative paths - relative to your storage directory 2. Absolute paths - if you want full control</p>"},{"location":"guides/LOADING_DATASETS/#basic-usage","title":"Basic Usage","text":""},{"location":"guides/LOADING_DATASETS/#option-1-using-virtualfilesystem-recommended","title":"Option 1: Using VirtualFilesystem (Recommended)","text":"<p>The <code>VirtualFilesystem</code> manages datasets for you with Unix-like paths:</p> <pre><code>from pathlib import Path\nfrom infinigram.vfs import VirtualFilesystem\n\n# Create VFS with a storage directory\n# This can be relative or absolute\nvfs = VirtualFilesystem(storage_dir=Path(\"./datasets\"))\n# OR\nvfs = VirtualFilesystem(storage_dir=Path.home() / \".infinigram\" / \"datasets\")\n\n# Load existing dataset by name (no path needed!)\ndataset = vfs.get_dataset(\"math\")\n\n# The dataset is located at: storage_dir/math/\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#option-2-using-dataset-directly","title":"Option 2: Using Dataset Directly","text":"<p>If you want direct control, use the <code>Dataset</code> class:</p> <pre><code>from pathlib import Path\nfrom infinigram.storage import Dataset\n\n# Relative path (relative to current working directory)\ndataset = Dataset(Path(\"./my_datasets/math\"))\n\n# Absolute path\ndataset = Dataset(Path(\"/home/user/datasets/math\"))\n\n# Using home directory\ndataset = Dataset(Path.home() / \"datasets\" / \"math\")\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#complete-examples","title":"Complete Examples","text":""},{"location":"guides/LOADING_DATASETS/#example-1-create-and-load-with-vfs","title":"Example 1: Create and Load with VFS","text":"<pre><code>from pathlib import Path\nfrom infinigram.vfs import VirtualFilesystem\n\n# Setup VFS with relative path\nvfs = VirtualFilesystem(storage_dir=Path(\"./infinigram_data\"))\n\n# Create a new dataset\nmath_dataset = vfs.create_dataset(\"math\")\n\n# Add some documents\nmath_dataset.add_document(\"Addition is combining numbers\")\nmath_dataset.add_document(\"Subtraction is the inverse of addition\")\nmath_dataset.add_tag(0, \"basics\")\n\n# Later, load the dataset (same session or different session)\nvfs2 = VirtualFilesystem(storage_dir=Path(\"./infinigram_data\"))\nloaded_dataset = vfs2.get_dataset(\"math\")\n\nprint(f\"Documents: {loaded_dataset.count_documents()}\")  # Output: 2\nprint(loaded_dataset.get_document(0))  # Output: \"Addition is combining numbers\"\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#example-2-direct-dataset-loading","title":"Example 2: Direct Dataset Loading","text":"<pre><code>from pathlib import Path\nfrom infinigram.storage import Dataset\n\n# Load dataset from relative path\ndataset = Dataset(Path(\"./data/my_corpus\"))\n\n# Add documents\ndataset.add_document(\"The cat sat on the mat\")\ndataset.add_tag(0, \"animals/cat\")\n\n# Later, load from the same path\ndataset2 = Dataset(Path(\"./data/my_corpus\"))\nprint(dataset2.count_documents())  # Output: 1\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#example-3-using-environment-variables","title":"Example 3: Using Environment Variables","text":"<pre><code>import os\nfrom pathlib import Path\nfrom infinigram.vfs import VirtualFilesystem\n\n# Get storage directory from environment variable\nstorage_dir = Path(os.getenv(\"INFINIGRAM_DATA\", \"./infinigram_data\"))\n\nvfs = VirtualFilesystem(storage_dir=storage_dir)\ndataset = vfs.get_dataset(\"my_dataset\")\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#path-resolution-details","title":"Path Resolution Details","text":""},{"location":"guides/LOADING_DATASETS/#virtualfilesystem","title":"VirtualFilesystem","text":"<p>When you use <code>VirtualFilesystem(storage_dir=Path(\"./datasets\"))</code>:</p> <ol> <li>The <code>storage_dir</code> is where ALL datasets are stored</li> <li>Each dataset is a subdirectory: <code>storage_dir/dataset_name/</code></li> <li>You access datasets by name, not by full path</li> </ol> <pre><code>./datasets/              # storage_dir\n\u251c\u2500\u2500 math/               # dataset \"math\"\n\u2502   \u251c\u2500\u2500 documents.jsonl\n\u2502   \u251c\u2500\u2500 index.db\n\u2502   \u2514\u2500\u2500 metadata.json\n\u251c\u2500\u2500 science/            # dataset \"science\"\n\u2502   \u251c\u2500\u2500 documents.jsonl\n\u2502   \u251c\u2500\u2500 index.db\n\u2502   \u2514\u2500\u2500 metadata.json\n\u2514\u2500\u2500 history/            # dataset \"history\"\n    \u251c\u2500\u2500 documents.jsonl\n    \u251c\u2500\u2500 index.db\n    \u2514\u2500\u2500 metadata.json\n</code></pre> <p>To load: <pre><code>vfs = VirtualFilesystem(Path(\"./datasets\"))\nmath_ds = vfs.get_dataset(\"math\")         # loads ./datasets/math/\nscience_ds = vfs.get_dataset(\"science\")   # loads ./datasets/science/\n</code></pre></p>"},{"location":"guides/LOADING_DATASETS/#dataset-direct","title":"Dataset Direct","text":"<p>When you use <code>Dataset(path)</code>:</p> <ol> <li>The <code>path</code> is the full path to the dataset directory</li> <li>Can be relative or absolute</li> <li>The directory contains: <code>documents.jsonl</code>, <code>index.db</code>, <code>metadata.json</code></li> </ol> <pre><code># These all work:\nDataset(Path(\"./my_data\"))                    # relative\nDataset(Path(\"/home/user/data\"))              # absolute\nDataset(Path.home() / \"infinigram\" / \"data\")  # home directory\nDataset(Path.cwd() / \"datasets\" / \"math\")     # current working dir\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#common-patterns","title":"Common Patterns","text":""},{"location":"guides/LOADING_DATASETS/#pattern-1-default-location","title":"Pattern 1: Default Location","text":"<pre><code>from pathlib import Path\nfrom infinigram.vfs import VirtualFilesystem\n\n# Use a consistent default location\nDEFAULT_STORAGE = Path.home() / \".infinigram\" / \"datasets\"\n\nvfs = VirtualFilesystem(storage_dir=DEFAULT_STORAGE)\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#pattern-2-project-local-data","title":"Pattern 2: Project-Local Data","text":"<pre><code>from pathlib import Path\nfrom infinigram.vfs import VirtualFilesystem\n\n# Store datasets in project directory\nvfs = VirtualFilesystem(storage_dir=Path(\"./data\"))\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#pattern-3-shared-system-data","title":"Pattern 3: Shared System Data","text":"<pre><code>from pathlib import Path\nfrom infinigram.vfs import VirtualFilesystem\n\n# System-wide location\nvfs = VirtualFilesystem(storage_dir=Path(\"/var/lib/infinigram/datasets\"))\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#checking-if-dataset-exists","title":"Checking if Dataset Exists","text":""},{"location":"guides/LOADING_DATASETS/#with-vfs","title":"With VFS","text":"<pre><code>vfs = VirtualFilesystem(Path(\"./datasets\"))\n\nif vfs.dataset_exists(\"math\"):\n    dataset = vfs.get_dataset(\"math\")\nelse:\n    dataset = vfs.create_dataset(\"math\")\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#with-dataset","title":"With Dataset","text":"<pre><code>from pathlib import Path\n\ndataset_path = Path(\"./datasets/math\")\n\nif dataset_path.exists():\n    dataset = Dataset(dataset_path)\nelse:\n    # Create new (Dataset creates directory automatically)\n    dataset = Dataset(dataset_path)\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#listing-available-datasets","title":"Listing Available Datasets","text":"<pre><code>vfs = VirtualFilesystem(Path(\"./datasets\"))\n\n# List all datasets\ndatasets = vfs.list_datasets()\nprint(f\"Available datasets: {datasets}\")\n\n# Load each one\nfor name in datasets:\n    ds = vfs.get_dataset(name)\n    print(f\"{name}: {ds.count_documents()} documents\")\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#error-handling","title":"Error Handling","text":"<pre><code>from infinigram.vfs import VirtualFilesystem\nfrom pathlib import Path\n\nvfs = VirtualFilesystem(Path(\"./datasets\"))\n\ntry:\n    dataset = vfs.get_dataset(\"nonexistent\")\nexcept FileNotFoundError as e:\n    print(f\"Dataset not found: {e}\")\n    # Create it instead\n    dataset = vfs.create_dataset(\"nonexistent\")\n</code></pre>"},{"location":"guides/LOADING_DATASETS/#best-practices","title":"Best Practices","text":""},{"location":"guides/LOADING_DATASETS/#recommended","title":"\u2705 Recommended","text":"<ol> <li>Use VirtualFilesystem for most cases - it manages paths for you</li> <li>Use relative paths for project-specific data</li> <li>Use <code>Path.home()</code> for user-specific data</li> <li>Check existence before loading if not sure dataset exists</li> </ol>"},{"location":"guides/LOADING_DATASETS/#avoid","title":"\u274c Avoid","text":"<ol> <li>Hard-coding absolute paths in code</li> <li>Using string paths instead of <code>Path</code> objects</li> <li>Creating datasets in system directories without permissions</li> </ol>"},{"location":"guides/LOADING_DATASETS/#summary","title":"Summary","text":"<p>To answer your question directly:</p> <pre><code># NO absolute path needed!\n\nfrom pathlib import Path\nfrom infinigram.vfs import VirtualFilesystem\n\n# Use relative path for storage directory\nvfs = VirtualFilesystem(Path(\"./my_datasets\"))\n\n# Load dataset by name (just the name, not a path!)\ndataset = vfs.get_dataset(\"math\")\n\n# The dataset is automatically loaded from: ./my_datasets/math/\n</code></pre> <p>The path you provide to <code>VirtualFilesystem()</code> can be relative or absolute - your choice! Then you access datasets by simple names, no paths needed.</p>"}]}